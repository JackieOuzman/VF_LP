---
# title: "Long Plains analysis for paper"
# author: "Jackie Ouzman"
# date: "30/10/2020"
# output:
# word_document: default
# html_document:
# code_folding: hide
# df_print: paged
title: "Long Plains"
author: "Jackie Ouzman"
date: "30/10/2020"
output:
  html_document:
    code_folding: hide
    df_print: paged
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```


```{r lib, message=FALSE, warning=FALSE, include=FALSE}
library(dplyr)
library(tidyverse)
library(readr)
library(lubridate)
library(DT)
library(sp)


library(rgdal)
library(sf)

#install.packages("plotKML")
library(plotKML)
library(knitr)
library(png)

library(readxl)


library(ggmap)
library(maps)
library(mapdata)

library(raster)
library(formattable)
#library(hms) Add these before I use them?
#library(plyr)
library(ggpubr)

```

# Long Plains VF trial

## Biomass readings

Crop circle and Phenom survey undertaken by Damian and Willie on XX/10/2020
Crop circle and Phenom survey undertaken by Damian on 6/11/2020

**Raw data**

- "\\FSSA2-ADL\clw-share1\Microlab\VF\LongPlain\CC\Crop Circle LP 2020 pre graze"
- "\\FSSA2-ADL\clw-share1\Microlab\VF\LongPlain\CC\Phenom LP 2020 pre graze"


- "\\FSSA2-ADL\clw-share1\Microlab\VF\LongPlain\CC\Crop Circle post graze"
- "\\FSSA2-ADL\clw-share1\Microlab\VF\LongPlain\CC\Phenom post graze"

**Rasters** 

- "W:\VF\LongPlain\CC\Crop Circle LP 2020 pre graze\LAI\Vesper\cc_all_HighDensity_LAI_VI_PRED_2m.tif"
- "W:\VF\LongPlain\CC\Crop Circle LP 2020 pre graze\NDVI\Vesper\cc_all_HighDensity_NDVI_PRED_2m.tif"

- "W:\VF\LongPlain\CC\Phenom LP 2020 pre graze\Phen_LAI\Vesper\Phen_all_HighDensity_LAI_VI_PRED_2m.tif"
- "W:\VF\LongPlain\CC\Phenom LP 2020 pre graze\Phen_NDVI\Vesper\cc_all_LAI_VI_HighDensity_NDVI_PRED_2m.tif"




- "W:\VF\LongPlain\CC\Crop Circle post graze\LAI\Vesper\CC_post_graze_HighDensity_LAI_VI_PRED_2m.tif"
- "W:\VF\LongPlain\CC\Crop Circle post graze\NDVI\Vesper\CC_post_graze_HighDensity_NDVI_PRED_2m.tif"

- "W:\VF\LongPlain\CC\Phenom post graze\Phen_LAI\Vesper\Phenommerged201106_HighDensity_LAI_VI_PRED_2m.tif"
- "W:\VF\LongPlain\CC\Phenom post graze\Phen_NDVI\Vesper\"Phenommerged201106_HighDensity_NDVI_PRED_2m.tif""


Data processing done by Jackie using the following settings:

- Data cleaned and trimmed using PAT QGIS tools, standard default settings used

- Block boundaries drawn based on GPS points

- Block grid of 2m pixel made

- Vesper used for kriging cleaned data

- Vesper setting include; block kriging with a block size of 10m

- Data in below map is displayed as quantile.

## Pre graze maps

```{r cc_pre_trial, echo=FALSE, message=FALSE, warning=FALSE}
# All defaults
include_graphics("W:/VF/LongPlain/CC/Pre_graze.png")


```



## Post graze maps

```{r cc_post_trial, echo=FALSE, message=FALSE, warning=FALSE}
# All defaults
include_graphics("W:/VF/LongPlain/CC/Post_graze.png")


```







## Location of fences

All hard fence corners and water points were GPS.

VF locations supplied by Agersens via email.

Raw data located:

"\\FSSA2-ADL\clw-share1\Microlab\VF\LongPlain\LP Blk Bound\VF_boundary_raw\cood_agersens.csv"


All points turned into shape files and mapped:

- "\\FSSA2-ADL\clw-share1\Microlab\VF\LongPlain\LP Blk Bound\LongPlainVF_bound.shp" 
- "\\FSSA2-ADL\clw-share1\Microlab\VF\LongPlain\LP Blk Bound\LongPlain_GDA_internal_bound.shp"
- "\\FSSA2-ADL\clw-share1\Microlab\VF\LongPlain\LP Blk Bound\Water_pts.shp"


```{r boundary map, echo=FALSE, message=FALSE, warning=FALSE}
# All defaults
include_graphics("W:/VF/LongPlain/LP Blk Bound/Boundary_map.png")


```

## Biomass measures / pasture cuts

- 19/10/2020        Pre graze weeds data was collected with no GPS 

- 26/10/2020        Biomass data with GPS pts and
                    Total weeds with GPS pts 

- 30/10/2020        Biomass with GPS pts and
                    Total weeds with GPS pts

- 03/11/2020        Biomass data with GPS pts
                    There are a few 0 values  
                    No weeds data  

- 06/11/2020        Biomass and weed data with GPS pts 
                   

- 09/11/2020        Weed data with GPS pts 



This has been collated into one excel file with multiple tabs and summary tab.

- "\\FSSA2-ADL\clw-share1\Microlab\VF\LongPlain\biomass\Biomass samples 2020_Jax.xlsx" 


## Location of biomass sampling

```{r biomass new, message=FALSE, warning=FALSE, include=FALSE}

#need to make df into spatial object for graphing and try clipping to paddock boundary
long_plains <- st_read("W:/VF/LongPlain/LP Blk Bound/LongPlain_GDA_internal_bound.shp")
long_plains_Vf <- st_read("W:/VF/LongPlain/LP Blk Bound/LongPlainVF_bound.shp")

####

Biomass_samples_2020_all <- read_excel("W:/VF/LongPlain/biomass/Biomass samples 2020_Jax.xlsx", 
    sheet = "All_Biomass", range = "A1:I101")

#unique(Biomass_samples_2020_all$Date)

#turn theses df into shapefiles
Biomass_samples_2020_all_sf <-
      st_as_sf(Biomass_samples_2020_all,
               coords = c("X", "Y"),
               crs = 4326,
               agr = "constant")

Biomass_samples_2020_all_sf_tran <-
      st_transform(Biomass_samples_2020_all_sf, crs = 28354)

str(Biomass_samples_2020_all_sf_tran)

biomass26_10 <- Biomass_samples_2020_all_sf_tran %>% 
  filter(Date ==  as.Date("2020-10-26")) #%>% 
  #select(Date, geometry)
biomass30_10 <- Biomass_samples_2020_all_sf_tran %>% 
  filter(Date ==  as.Date("2020-10-30")) #%>% 
  #select(Date, geometry)
biomass3_11 <- Biomass_samples_2020_all_sf_tran %>% 
  filter(Date ==  as.Date("2020-11-03")) #%>% 
  #select(Date, geometry)
biomass06_11 <- Biomass_samples_2020_all_sf_tran %>% 
  filter(Date ==  as.Date("2020-11-06")) #%>% 
  #select(Date, geometry)




```



```{r biomass_plot locations, echo=FALSE, message=FALSE, warning=FALSE}




ggplot() +
    geom_sf(data = long_plains, color = "black", fill = NA) +
    geom_sf(data= biomass26_10, aes(color="A"), show.legend = "point") +
    geom_sf(data= biomass30_10, aes(color="B"), show.legend = "point") +
    geom_sf(data= biomass3_11, aes(color="C"), show.legend = "point") +
    geom_sf(data= biomass06_11, aes(color="D"), show.legend = "point") +
    scale_color_manual(values = c("A" = "red", "B" = "blue",  "C" = "grey" ,  "D" = "black"),
                       labels = c("26/10", "30/10", "3/11","6/11" ),
                       name = "Biomass cuts")+
  theme_bw()+
  theme(axis.ticks = element_blank(), axis.text.x = element_blank(), axis.text.y = element_blank())


```






**In order to match the biomass information to the Pinnaroo site I will use Phenom Dist post graze**

## plot of biomass vs survey data pre trial

Linear model 

Need to convert biomass in grams to Kg/ha to match Pinnaroo dataset.

```{r pre_trial biomass vs biomass survey, echo=FALSE, message=FALSE, warning=FALSE}

post_trial_biomass <- read.csv("W:/VF/LongPlain/biomass/Biomass_vsPhen_DIST.csv")
#select only the pre trial data pts.
#names(post_trial_biomass)
#rename some clm this is the order that was extered when extrcated in Arcmap
post_trial_biomass <- read.csv("W:/VF/LongPlain/biomass/Biomass_vsPhen_DIST_1.csv")
#convert biomass in grams to biomass in kg/ha

#str(post_trial_biomass)
post_trial_biomass <- post_trial_biomass %>% 
  dplyr::mutate(biomass_Kg = biomass_g *0.001,
                sample_size_hectare = 0.000025, #based on a quadrat size of 50*50cm
                biomass_Kg_ha = biomass_Kg / sample_size_hectare)
                


post_trial_biomass <- post_trial_biomass %>%
  rename(
    Survey_Phen_NDVI = NDVI_Phen,
    Survey_Phen_LAI = LAI_Phen_,
    Survey_Phen_DIST = RASTERVALU
  )


#### how does the biomass pre trial relate to the pre trial biomass survey data?
#unique(post_trial_biomass$timing)
post_trial_biomass <- post_trial_biomass %>% 
  filter(timing == "3 days before end of trial")


#let rearragne the data so I can do a facet wrap
post_trial_biomass_long <- post_trial_biomass %>% 
  pivot_longer(cols = starts_with("Survey"),
               names_to = "survey_type",
               values_to = "value")

#pre_trial_biomass_long %>%  group_by(survey_type) %>%  summarise(count = n()) #22

#http://www.sthda.com/english/wiki/ggplot2-scatter-plots-quick-start-guide-r-software-and-data-visualization
# method : smoothing method to be used. Possible values are lm, glm, gam, loess, rlm.
# method = “loess”: This is the default value for small number of observations. It computes a smooth local regression. You can read more about loess using the R code ?loess.
# method =“lm”: It fits a linear model. Note that, it’s also possible to indicate the formula as formula = y ~ poly(x, 3) to specify a degree 3 polynomial.
# se : logical value. If TRUE, confidence interval is displayed around smooth.
# fullrange : logical value. If TRUE, the fit spans the full range of the plot
# level : level of confidence interval to use. Default value is 0.95
#post_trial_biomass_long


plot1 <- post_trial_biomass_long %>%
  #filter(survey_type == "Survey_CC_NDVI") %>% 
  ggplot(aes(x = value  , y =  biomass_Kg_ha)) +
  geom_point()+
  geom_smooth(mapping = aes(x = value  , y =  biomass_Kg_ha,group = survey_type),
              method = lm, se = FALSE)+
  #geom_smooth(se = FALSE)+
  facet_wrap(.~survey_type, scales = "free_x")+
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90))+
  labs(
    x = paste0("survey data"),
    y = "biomass cuts kg/ ha",
    title = "Post trial data"
  )
plot1

```


## The fit of models biomass vs survey data pre trial




```{r pre_trial biomass vs biomass survey model fit1, echo=FALSE, message=FALSE, warning=FALSE}



#http://www.sthda.com/english/articles/40-regression-analysis/167-simple-linear-regression-in-r/




post_trial_biomass_long_Phen_DIST <- post_trial_biomass_long %>% 
  filter(survey_type == "Survey_Phen_DIST")
post_trial_biomass_long_Phen_NDVI <- post_trial_biomass_long %>% 
  filter(survey_type == "Survey_Phen_NDVI")
post_trial_biomass_long_Phen_LAI <- post_trial_biomass_long %>% 
  filter(survey_type == "Survey_Phen_LAI")

#names(post_trial_biomass_long_Phen_DIST)


cor_pre_Phen_DIST <- cor(post_trial_biomass_long_Phen_DIST$value, 
                         post_trial_biomass_long_Phen_DIST$biomass_Kg_ha) 

cor_pre_Phen_NDVI <- cor(post_trial_biomass_long_Phen_NDVI$value, 
                         post_trial_biomass_long_Phen_NDVI$biomass_Kg_ha)

cor_pre_Phen_LAI <- cor(post_trial_biomass_long_Phen_LAI$value, 
                         post_trial_biomass_long_Phen_LAI$biomass_Kg_ha)


#Make a table with the analysis correlation table

post_trial_table <- data.frame(survey  = c( "NDVI","LAI","DIST"),
                               survey_type  = c("Phenom", "Phenom", "Phenom" ),
                               correlation = c( cor_pre_Phen_NDVI, cor_pre_Phen_LAI, cor_pre_Phen_DIST ),
                               timing  = c( "post_trial"))


model_post_Phen_NDVI <- summary(lm(biomass_Kg_ha ~ value, 
                                   data = post_trial_biomass_long_Phen_NDVI))

model_post_Phen_LAI <- summary(lm(biomass_Kg_ha ~ value, 
                                   data = post_trial_biomass_long_Phen_LAI))

model_post_Phen_DIST <- summary(lm(biomass_Kg_ha ~ value, 
                                   data = post_trial_biomass_long_Phen_DIST))

# model_pre_CC_NDVI
# model_pre_CC_NDVI$coefficients[1,1] #b0 Intercept
# model_pre_CC_NDVI$coefficients[2,1] #b1 slope
# model_pre_CC_NDVI$sigma #(Residual Standard Error from Linear Regression Model)
# model_pre_CC_NDVI$adj.r.squared
# model_pre_CC_NDVI$r.squared

#add this info to the pre_trial_table

post_trial_model_table <- data.frame(survey  = c("NDVI", "LAI", "DIST"),
                                     survey_type  = c("Phenom", "Phenom","Phenom" ),
                                     
                                     Intercept = c(model_post_Phen_NDVI$coefficients[1,1],
                                                   model_post_Phen_LAI$coefficients[1,1],
                                                   model_post_Phen_DIST$coefficients[1,1]),
                                     
                                     Slope = c( model_post_Phen_NDVI$coefficients[2,1],
                                                model_post_Phen_LAI$coefficients[2,1],
                                                model_post_Phen_DIST$coefficients[2,1]),
                                     
                                     RSE = c( model_post_Phen_NDVI$sigma,
                                              model_post_Phen_LAI$sigma,
                                              model_post_Phen_DIST$sigma),
                                     
                                     R_Square = c(model_post_Phen_NDVI$r.squared,
                                                  model_post_Phen_LAI$r.squared,
                                                  model_post_Phen_DIST$r.squared),
                                     
                                     Adj_R_Square = c( model_post_Phen_NDVI$adj.r.squared,
                                                       model_post_Phen_LAI$adj.r.squared,
                                                       model_post_Phen_DIST$adj.r.squared)
)




post_trial_model <- left_join(post_trial_table, post_trial_model_table)
post_trial_model
post_trial_model <- post_trial_model[, c(4, 1, 2, 3, 5,6,7,8)]

datatable(post_trial_model,
          options = list(dom = 't'),#removes the search bar
          caption = 'Details of the models.',
          rownames = FALSE)%>%
  formatRound(c(4,8), 2) %>% 
  formatRound(5:7, 0)
```



All correlation and R2 are terrible.

But if you needed to get a biomass map I would choose phenom dist - just so it matches the Pinnaroo data.

With this data set I would be reluctant converting survey data to biomass in Kg per ha.

But I guess if you had to this would look like this:

`summary(lm( BM__kg___H~  value, data = pre_trial_biomass_long_Phen_DIST_pre))`


```{r pre_trial biomass vs biomass survey best model fit, echo=FALSE, message=FALSE, warning=FALSE}
post_trial_biomass_long_Phen_DIST <- post_trial_biomass_long %>% 
  filter(survey_type == "Survey_Phen_DIST")

summary(lm( biomass_Kg_ha~  value, data = post_trial_biomass_long_Phen_DIST))
```

### An option for converting survey data to biomass in kg/ha -  POST TRIAL

biomass = intercept + slope * survey

biomass = -2951.49 + 65.11 * Phenom Dist survey value


## Post trial maps

```{r phenom post_trial, echo=FALSE, message=FALSE, warning=FALSE}

include_graphics("W:/VF/LongPlain/CC/biomass.png")


```


### Notes / observation from the above maps.

- I have only created a biomass map for post trial, we don't have biomass cut for the pre trial.
- I have converted Damian biomass cuts to kg/ha with the assumption of the size (I need to check).
- The correlation and R2 are poor and this could relate to the lack of vegetation, other signals are no better.
- we should consider if this data is good enough to present.
- the VF 1 shows as having lowest biomass.
- buffer does not have higher biomass than grazed parts of the paddock.
- we can't assume different parts of the paddock at a fixed time is due to grazing.



| Summary Stat for biomass post paddock (from .tif files)	        | 
| ------- | ----------|----------|-------|-------|
| stat    |whole paddock| Control| Buffer| VF    |
| Min     |105.6      |   254.6  |228.7  |105.6  |
| Max     |1122.4     |   1007.5 |1012.7 |1122.4 |
| **Mean**    |**620.8**      |	  **661.1**  |**603.1**  |**585.6**  |
| Std Dev |145.9      |   134.4  |112    |159.5  |








### Average biomass cut values for select dates

One of the aims here was to assess the biomass cover and grazing pressure with each fence move.

The sampling was done in a wider area, but I have just taken a subset of the data to create sampling events.

For example we are interested in how much biomass is left on the 26/10/2020 in VF area 1.

biomass_sampling_event1 is samples collected 26/10/2020 in VF area 1

biomass_sampling_event2 is samples collected 30/10/2020 in VF area 1 and 2

biomass_sampling_event3 is samples collected 03/11/2020 in VF area 1, 2 and 3

biomass_sampling_event4 is samples collected 06/11/2020 in VF area 1, 2, 3 and 4




```{r biomass cuts ave, echo=FALSE, message=FALSE, warning=FALSE}

Biomass_samples_2020_all <- read_excel("W:/VF/LongPlain/biomass/Biomass samples 2020_Jax.xlsx", 
                                       sheet = "All_Biomass", 
                                       range =  "A1:M101", #13clms
                                       col_types = c("date",   "text", "text", 
                                                     "numeric", "numeric", 
                                                     
                                                     "text", "text",
                                                     "numeric", "numeric", "numeric", "numeric", "numeric", "numeric"))

# names(Biomass_samples_2020_all)
Biomass_samples_2020_all <- Biomass_samples_2020_all %>% 
  dplyr::select(Date:Paddock, `biomass_Kg/ha`)

# str(Biomass_samples_2020_all)
# unique(Biomass_samples_2020_all$Paddock)


Biomass_samples_2020_all <- Biomass_samples_2020_all %>%
  mutate(
     VF_area_sampling = case_when(
      Date == as.Date("2020-10-26") &
        Paddock == "VF1" ~ "biomass_sampling_event1",
      
      Date == as.Date("2020-10-30") & Paddock == "VF1" |
      Date == as.Date("2020-10-30") & Paddock == "VF2"   ~ "biomass_sampling_event2",
      
      Date == as.Date("2020-11-03") & Paddock == "VF1" |
      Date == as.Date("2020-11-03") & Paddock == "VF2" | 
      Date == as.Date("2020-11-03") & Paddock == "VF3"   ~ "biomass_sampling_event3",
      
      Date == as.Date("2020-11-06") & Paddock == "VF1" |
      Date == as.Date("2020-11-06") & Paddock == "VF2" | 
      Date == as.Date("2020-11-06") & Paddock == "VF3" | 
      Date == as.Date("2020-11-06") & Paddock == "VF4"   ~ "biomass_sampling_event4",
      
      
    )
  )

Biomass_samples_2020_all <- Biomass_samples_2020_all %>% 
  filter(!is.na(VF_area_sampling))

biomass_ave <- Biomass_samples_2020_all %>%
  group_by(Date, VF_area_sampling ) %>%
  summarise(average_biomass = mean(`biomass_Kg/ha`, na.rm = TRUE),
            SD_biomass = sd(`biomass_Kg/ha`, na.rm = TRUE),
            count = n()) %>%
  mutate(average_biomass = round(average_biomass,2),
         SD_biomass = round(SD_biomass,2))

#biomass_ave












```


```{r biomass cuts graph, echo=FALSE, message=FALSE, warning=FALSE}
 # mutate(average_biomass = round(average_biomass,2),
 #         SD_biomass = round(SD_biomass,2))



biomass_ave %>% 
  formattable()

```







## Weed counts

- **Pre grazing weed data done on 19/10 no GPS location**

- 26/10/2020 - no GPS - total counts 

- 30/10/2020 - no GPS - total counts

- 03/11/2020 - no GPS - total counts

- 06/11/2020 - no GPS - total counts

- **9/11/2020 - GPS - post grazing**  


This has been collated into one excel file with multiple tabs and summary tab.

- "\\FSSA2-ADL\clw-share1\Microlab\VF\LongPlain\biomass\Biomass samples 2020_Jax.xlsx" 




```{r weeds_09_11_data, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}

#need to make df into spatial object for graphing and try clipping to paddock boundary
long_plains <- st_read("W:/VF/LongPlain/LP Blk Bound/LongPlain_GDA_internal_bound.shp")
long_plains_Vf <- st_read("W:/VF/LongPlain/LP Blk Bound/LongPlainVF_bound.shp")




weeds <- read_excel("W:/VF/LongPlain/biomass/Biomass samples 2020_Jax.xlsx", 
    sheet = "All_Weeds", col_types = c("date", 
        "text", "text", "numeric", "numeric", "text", 
        "text", "text", "numeric", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric", "text"))


weeds_GPS <- weeds %>%  filter(X != "NA")


weeds_GPS_sf <-
      st_as_sf(weeds_GPS,
               coords = c("X", "Y"),
               crs = 4326,
               agr = "constant")

weeds_GPS_sf_tran <-
      st_transform(weeds_GPS_sf, crs = 28354)


```


```{r weeds_19_11_plot, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
#unique(weeds_GPS_sf_tran$Date)


weeds26_10 <- weeds_GPS_sf_tran %>% 
  filter(Date ==  as.Date("2020-10-26")) 
weeds30_10 <- weeds_GPS_sf_tran %>% 
  filter(Date ==  as.Date("2020-10-30")) 
weeds06_11 <- weeds_GPS_sf_tran %>% 
  filter(Date ==  as.Date("2020-11-06")) 
weeds09_11 <- weeds_GPS_sf_tran %>% 
  filter(Date ==  as.Date("2020-11-09")) 



ggplot() +
    geom_sf(data = long_plains, color = "black", fill = NA) +
    geom_sf(data= weeds26_10, aes(color="A"), show.legend = "point") +
    geom_sf(data= weeds30_10, aes(color="B"), show.legend = "point") +
    geom_sf(data= weeds06_11, aes(color="C"), show.legend = "point") +
    geom_sf(data= weeds09_11, aes(color="D"), show.legend = "point") +
    scale_color_manual(values = c("A" = "red", "B" = "blue",  "C" = "grey" ,  "D" = "black"),
                       labels = c("26/10", "30/10", "6/11","9/11" ),
                       name = "weed counts")+
  theme_bw()+
  theme(axis.ticks = element_blank(), axis.text.x = element_blank(), axis.text.y = element_blank())






```




```{r weeds count clm Plots1, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}


#str(weeds)
weed_pre_graze <- weeds %>% 
  filter(timing == "pre_graze")


weed_av_pre_graze <- weeds %>% 
  filter(timing == "pre_graze") %>% 
  group_by(Location) %>% 
  summarise(Total_weed_av = mean(total_weeds, na.rm = TRUE),
            Ryegrass_av = mean(`Rye Grass`, na.rm = TRUE),
             Sow_thistle_av = mean(`Sow_thistle`, na.rm = TRUE),
            Brassica_av = mean(`Brassica`, na.rm = TRUE))

#weed_av_pre_graze

weed_av_pre_graze %>%
  ggplot(aes(x = Location , y = Total_weed_av)) +
  geom_col()+
  theme_classic() +
    theme(axis.text.x = element_text(angle = 90))+
  labs(
    x = "Location",
    y = "Average total weed count per sampling area",
    title = paste("Total weed counts - pre graze")
  )

weed_av_pre_graze %>%
  ggplot(aes(x = Location , y = Ryegrass_av)) +
  geom_col()+
  theme_classic() +
    theme(axis.text.x = element_text(angle = 90))+
  labs(
    x = "Location",
    y = "Average Ryegrass plants per sampling area",
    title = paste("Number of Ryegrass plants - pre graze")
  )

weed_av_pre_graze %>%
  ggplot(aes(x = Location , y = Sow_thistle_av)) +
  geom_col()+
  theme_classic() +
    theme(axis.text.x = element_text(angle = 90))+
  labs(
    x = "Location",
    y = "Average Sow Thistle plants per sampling area ",
    title = paste("Number of Sow Thistle plants - pre graze")
  )

```









## Pre and post grazing for paper.

The analysis of the count data should not be done with t.test or anova.

Poisson regression is a good option

https://rcompanion.org/handbook/J_01.html

# Average table

```{r weeds results for paper, echo=FALSE, message=FALSE, warning=FALSE}
weeds1 <- read_excel("W:/VF/LongPlain/biomass/Biomass samples 2020_Jax.xlsx", 
                    sheet = "All_Weeds", col_types = c("date", 
                                                       "text", "text", "numeric", "numeric", "text", 
                                                       "text", "text", "numeric", "numeric", 
                                                       "numeric", "numeric", "numeric", 
                                                       "numeric", "text"))
                          

#str(weeds)
weeds1 <- weeds1 %>% mutate(
  pre_post = case_when(
    timing == "pre_graze" ~ "pre graze",
    timing == "last day of trial" ~ "post graze",
  )
)

weeds1 <- weeds1 %>%  dplyr::filter(!is.na(pre_post))

#unique(weeds$Location)

weeds1 <- weeds1 %>% mutate(
  location_2 = case_when(
    Location == "VF" ~ "VF",
    Location == "buffer" ~ "open-graze",
    Location == "control" ~ "ungrazed"
  )
)

#str(weeds)
weeds1 <- weeds1 %>% dplyr::select(pre_post, location_2, total_weeds, "Rye Grass", heads)

weeds_summary <- weeds1 %>% group_by(pre_post, location_2) %>%
  summarise(
    av_total_weeds =     mean(total_weeds, na.rm = TRUE),
    st_dev_total_weeds = sd(total_weeds, na.rm = TRUE),
  
    av_Rye_Grass = mean(`Rye Grass`, na.rm = TRUE),
    st_dev_Rye_Grass = sd(`Rye Grass`, na.rm = TRUE),
       
    
    av_heads = mean(heads, na.rm = TRUE),
    st_dev_heads = sd(heads, na.rm = TRUE))



weeds_summary <- weeds_summary %>% 
  mutate(av_total_weeds = round(av_total_weeds,2),
          st_dev_total_weeds = round(st_dev_total_weeds,2),
         
         av_Rye_Grass = round(av_Rye_Grass,2),
          st_dev_Rye_Grass = round(st_dev_Rye_Grass,2),
         
         av_heads = round(av_heads,2),
          st_dev_heads = round(st_dev_heads,2)
         
         )



weeds_summary %>% 
  formattable()


```

# Sum table

Note that the head count was not performed in the pre graze assessment

```{r weeds counts results for paper, echo=FALSE, message=FALSE, warning=FALSE}



weeds_summary_total_sum <- weeds1 %>% group_by(pre_post, location_2) %>%
  summarise(
    sum_total_weeds =     sum(total_weeds, na.rm = TRUE),
    sum_Rye_Grass =       sum(`Rye Grass`, na.rm = TRUE),
    sum_heads =           sum(heads, na.rm = TRUE))
   
#weeds_summary_total_sum


summary_total_sum <- weeds_summary_total_sum %>% 
  mutate(sum_total_weeds = round(sum_total_weeds,2),
          sum_Rye_Grass = round(sum_Rye_Grass,2),
         
         sum_heads = round(sum_heads,2)
         
         )



summary_total_sum %>% 
  formattable()


```














## Start of trial and movement of fences

Start of trial activation_fence1 2020-10-21 14:55:00

End of trail 2020-11-09 09:00:00 (not sure the exact time)

Activation of the fences can be obtained from the eshepherd website.

- https://www.eshepherd.com/login 

Log in details are:
Jim.Lea@csiro.au
cs1roP@ss

There is about a 10 min lag between the time of the request and the activation of the fence.

The time of the requested fence change is reported in local time for the user.

For example if you log into the website in NSW the requested time is reported in EST,
but if you log into the website in SA it is reported in ACT.


ACT local time:

- activation_fence1 2020-10-21 14:55:00
- activation_fence2 2020-10-25 10:50:00
- activation_fence3 2020-10-30 08:03:00
- *deactivation_fence4* 2020-10-03 11:56:00




**Other notes for animals and weather**

Nigel is 1719 (9380672) and is in the control group he spends lots of time away from the mob.

Problem child / fence jumper 1632 (9380384).

Very cold windy day XXX?
Hot day 3/11/2020


## Background information on animal collar data from Agersens

The data will be downloaded from the cloud by Agersens every Monday.

The data exports are available on the Amazon S3 Bucket, Jim has login details for this.

The chief data scientist/ data analytics manager is:

DR. TANUSRI BHATTACHARYA
Chief Data Scientist/ Data Analytics Manager
email: tbhattacharya@agersens.com

The data is different to previous years and is aggregated in different ways.

Every 10 mins generates a new row of data.

This can be viewed from the timeOfEvent column.

**timeOfEvent**

Note that this timeOfEvent has a date and time stamp which is in GMT.

The *timeOfEvent* will need to be converted to local time.
Which is 10.5 hrs difference.

**GPS**

The GPS data is a snapshot of the location of the animals in a 10 min window.

Data columns that are supplied:

- *gpsData.lat*	
- *gpsData.lng*
- *gpsData.velocity_cm_s*	
- *gpsData.hdop_deci*	

I will use the lat and long column to create a location of the animal in the 10 min window.

The accuracy of this reading can be viewed within this 10 min window.


I am not sure about the velocity and hdop columns.

hdop is normally tells us about the accuracy of the GPS reading, but if the point is only logged every 10 mins would this be useful ?

I am also not sure about the use of the velocity reading, how would this be calculated if only one GPS record was logged every 10mins? 


**Stimuli - cue and audio readings**

The *cumulativeAudioCount* and	*cumulativeShockCount* columns are a running total of how many stimuli the animal has received since the start of the trial, and is re calculated every 10 mins.

It appears that the increments are not reset when a new fence is implement.
Instead its just keeps cumulating.

**Device details**

The *deviceName* is the name of the collar, more details about the mob can be found on the shared drive.

"\\FSSA2-ADL\clw-share1\Microlab\VF\LongPlain\Animal_ID\CSIROAnimalUpload-2020-10-20 Jim.xlsx" 

There is another columns which has information about the device this is called *deviceUIDHex*.

I am not using this column.


**Virtual Fence**


There is a column which is called *minDistanceToIZ*, which is the distance of the animal to the VF.

I am not sure if this is the min distance the animal got to the fence in the 10 min window or its the distance calculated from the logged GPS point in the file in the 10 mins window.

If it is the min distance the animal got to and not just the distance from the fence in the 'snap shot' this would be useful.

Column called *fencesID* is the name of the fence we have 2 files, the VF and control.
VF data:
The fence names in this column don't match what appears on the website.

- 1900  - fence 1 
- 1922f - fence 2 
       

The blank data in for the *fencesID* column has two categories.


- minDistanceToIZ = -1000000
- minDistanceToIZ = no data.

The data points with a blank fencesID id and aminDistanceToIZ = -1000000 has lying and standing values.

While the data points with a blank fencesID id and minDistanceToIZ = NA has **no** lying and standing values.

Tanusri has suggested:

*"If the values in “fenceID” column as blank, this means there is no active virtual fence for that neckband yet. Therefore, if you are performing some analysis related to virtual fencing, you can ignore those rows with blank fenceIDs."*


**Animal activity**

There are 4 columns that relate to the 
- *resting%*	
- *moving%*
- *grazing%* 

- *AwakeTime%*

The first 3 should add up to 100% and this is a sum value for the 10 min of time.

For example in the 10 min window the animals has spent 37% of the time resting, 30% moving and 33% grazing.

I need to double check this with Dana.


The Awake Time is different and won't add to the 100%.

I am not sure when this data column could be useful, any ideas Dana?




## Data manipulation (Methods)

## Step 1 bring in the raw data and set date and time formats

Week 1 download data two files for each week:

- csiro_weeklyexports_ending_2020-10-26
- csiro_weeklyexports_novf_ending_2020-10-27
- Monday and Tuesday


Week2 

- csiro_weeklyexports_ending_2020-11-02.csv
- csiro_weeklyexports_novf_ending_2020-11-03.csv
- Monday and Tuesday

Week3 

- csiro_weeklyexports_novf_ending_2020-11-09.csv
- csiro_weeklyexports_ending_2020-11-09.csv
- Monday this was the end of trial

Week4 (not sure if we need this data)

- "csiro_weeklyexports_novf_ending_2020-11-16.csv"
- "csiro_weeklyexports_ending_2020-11-16.csv"
- Monday


Set the date and time column to GMT and then display as local time.

**For the VF dataset I am only retaining data points that have an associated fence ID.**

Need to double check this - this is based on advice from Agersens.


**I need some help here??**

I want to make a clm that will help identify what part of the paddock the cows are allowed to graze in.

For VF 1 - 3 this is easy.
The data has an clm with 'fence ID', so when a VF is active this clm will have the fence ID value in it.
There is a problem with some logged points, the fence ID clm is blank.
I assume this is happening because the VF is deactivated.
Agersens suggested "For the VF dataset only retaining data points that have an associated fence ID".


But this is a problem because when it comes to the VF4 paddock.
The cows were allowed to graze in this last paddock,
but no VF was active, hence the fence ID clm don't have any values.


So I have created some new clms to help ID the animals and the VF paddocks 

group = control or VF

week_numb = "week1", "week2" or "week3"

Add date column - this is has no rounding and is just the date extracted from the local time column

fencesID_1  = 

"fence1"        = fencesID  == "19000" & group == VF 

"fence2"        = fencesID  == "1922f" & group == VF

"fence3"        = fencesID  == "11eab" & group == VF

"deactive_VF3"  = group == "VF" & local_time >= "2020-11-03 11:57:00"

"no_VF"         = group == "control"

"deactive_VF"   = everything else


I have also filter out data within a date and time range

between "2020-10-21 15:07:00" to "2020-11-09 09:00:00"


```{r bring in the data week 1, include=FALSE}
csiro_weeklyexports_ending_2020_10_26 <- read.csv("C:/Users/ouz001/working_from_home/VF_Long_plain/logged_cattle/csiro_weeklyexports_ending_2020-10-26.csv")
csiro_weeklyexports_novf_ending_2020_10_27 <- read.csv("C:/Users/ouz001/working_from_home/VF_Long_plain/logged_cattle/csiro_weeklyexports_novf_ending_2020-10-27.csv")


csiro_weeklyexports_ending_2020_10_26 <- csiro_weeklyexports_ending_2020_10_26 %>% 
  mutate(GMT = ymd_hms(timeOfEvent, tz = "GMT"),
         group = "VF")
csiro_weeklyexports_ending_2020_10_26 <- csiro_weeklyexports_ending_2020_10_26 %>% 
  mutate(local_time = with_tz(GMT, tz = "Australia/Adelaide"))


csiro_weeklyexports_novf_ending_2020_10_27 <- csiro_weeklyexports_novf_ending_2020_10_27 %>% 
  mutate(GMT = ymd_hms(timeOfEvent, tz = "GMT"),
         group = "control")
csiro_weeklyexports_novf_ending_2020_10_27 <- csiro_weeklyexports_novf_ending_2020_10_27 %>% 
  mutate(local_time = with_tz(GMT, tz = "Australia/Adelaide"))

#str(csiro_weeklyexports_ending_2020_10_26)
#str(csiro_weeklyexports_novf_ending_2020_10_27)

### remove all the NA for fence ID
# unique(csiro_weeklyexports_ending_2020_10_26$fencesID)
# csiro_weeklyexports_ending_2020_10_26 <- filter(csiro_weeklyexports_ending_2020_10_26, !is.na(fencesID))
# csiro_weeklyexports_ending_2020_10_26 <- filter(csiro_weeklyexports_ending_2020_10_26, 
#                                                 fencesID== "19000" |  fencesID== "1922f" )

week1 <- bind_rows(csiro_weeklyexports_ending_2020_10_26, csiro_weeklyexports_novf_ending_2020_10_27)
week1 <- week1 %>%  mutate(week_numb = "week1",
                           Fence_code = fencesID)


rm(csiro_weeklyexports_ending_2020_10_26, csiro_weeklyexports_novf_ending_2020_10_27)
```


```{r bring in the data week 2, include=FALSE}

#- csiro_weeklyexports_ending_2020-11-02.csv
#- csiro_weeklyexports_novf_ending_2020-11-03.csv
#"W:/VF/LongPlain/Collar_data/csiro_weeklyexports_ending_2020-11-09.csv"

csiro_week2exports_ending_2020_11_02 <- read.csv("W:/VF/LongPlain/Collar_data/csiro_weeklyexports_ending_2020-11-02.csv")
csiro_week2exports_novf_ending_2020_11_03 <- read.csv("W:/VF/LongPlain/Collar_data/csiro_weeklyexports_novf_ending_2020-11-03.csv")


csiro_week2exports_ending_2020_11_02 <- csiro_week2exports_ending_2020_11_02 %>% 
  mutate(GMT = ymd_hms(timeOfEvent, tz = "GMT"),
         group = "VF")
csiro_week2exports_ending_2020_11_02 <- csiro_week2exports_ending_2020_11_02 %>% 
  mutate(local_time = with_tz(GMT, tz = "Australia/Adelaide"))


csiro_week2exports_novf_ending_2020_11_03 <- csiro_week2exports_novf_ending_2020_11_03 %>% 
  mutate(GMT = ymd_hms(timeOfEvent, tz = "GMT"),
         group = "control")
csiro_week2exports_novf_ending_2020_11_03 <- csiro_week2exports_novf_ending_2020_11_03 %>% 
  mutate(local_time = with_tz(GMT, tz = "Australia/Adelaide"))

#str(csiro_week2exports_ending_2020_11_02)
#str(csiro_week2exports_novf_ending_2020_11_03)

### remove all the NA for fence ID
# unique(csiro_week2exports_ending_2020_11_02$fencesID)
# csiro_week2exports_ending_2020_11_02 <- filter(csiro_week2exports_ending_2020_11_02, !is.na(fencesID))
# csiro_week2exports_ending_2020_11_02 <- filter(csiro_week2exports_ending_2020_11_02, 
#                                                 fencesID== "11eab" |  fencesID== "1922f" )

week2 <- bind_rows(csiro_week2exports_ending_2020_11_02, csiro_week2exports_novf_ending_2020_11_03)
week2 <- week2 %>%  mutate(week_numb = "week2",
                           Fence_code = fencesID)



rm(csiro_week2exports_ending_2020_11_02, csiro_week2exports_novf_ending_2020_11_03)
```


```{r bring in the data week 3, include=FALSE}

#csiro_weeklyexports_novf_ending_2020-11-09.csv
#csiro_weeklyexports_ending_2020-11-09.csv


csiro_week3exports_ending_2020_11_09 <- read.csv("W:/VF/LongPlain/Collar_data/csiro_weeklyexports_ending_2020-11-09.csv")
csiro_week3exports_novf_ending_2020_11_09 <- read.csv("W:/VF/LongPlain/Collar_data/csiro_weeklyexports_novf_ending_2020-11-09.csv")


csiro_week3exports_ending_2020_11_09 <- csiro_week3exports_ending_2020_11_09 %>% 
  mutate(GMT = ymd_hms(timeOfEvent, tz = "GMT"),
         group = "VF")
csiro_week3exports_ending_2020_11_09 <- csiro_week3exports_ending_2020_11_09 %>% 
  mutate(local_time = with_tz(GMT, tz = "Australia/Adelaide"))


csiro_week3exports_novf_ending_2020_11_09 <- csiro_week3exports_novf_ending_2020_11_09 %>% 
  mutate(GMT = ymd_hms(timeOfEvent, tz = "GMT"),
         group = "control")
csiro_week3exports_novf_ending_2020_11_09 <- csiro_week3exports_novf_ending_2020_11_09 %>% 
  mutate(local_time = with_tz(GMT, tz = "Australia/Adelaide"))



### remove all the NA for fence ID
# unique(csiro_week3exports_ending_2020_11_09$fencesID)
# csiro_week3exports_ending_2020_11_09 <- filter(csiro_week3exports_ending_2020_11_09, !is.na(fencesID))
# csiro_week3exports_ending_2020_11_09 <- filter(csiro_week3exports_ending_2020_11_09, 
#                                                 fencesID== "11eab"  )

week3 <- bind_rows(csiro_week3exports_ending_2020_11_09, csiro_week3exports_novf_ending_2020_11_09)
week3 <- week3 %>%  mutate(week_numb = "week3",
                           Fence_code = fencesID)
rm(csiro_week3exports_ending_2020_11_09, csiro_week3exports_novf_ending_2020_11_09)
```

### Table for chceking time of fence moves

```{r append week 1 2 and 3, echo=FALSE, message=FALSE, warning=FALSE}

# unique(week1$fencesID)
# unique(week2$fencesID)
# unique(week3$fencesID)
# 
# unique(week1$week_numb)
# unique(week2$week_numb)
# unique(week3$week_numb)

week1_2_3 <- rbind(week1, week2, week3)
week1_2_3 <- week1_2_3 %>% 
  mutate(date = as.Date(local_time, tz= "Australia/Adelaide"),
         DOY = yday(date))


# filter out data within a date and timme range

week1_2_3 <- week1_2_3 %>%  filter(local_time >= ymd_hms("2020-10-21 15:07:00", tz= "Australia/Adelaide"), 
                    local_time <=  ymd_hms("2020-11-09 09:00:00", tz= "Australia/Adelaide"))


# check_import <- week1_2_3 %>% 
#   group_by(date, group) %>% 
#   summarise(reading = n())  
# 
# check_import

# create a new fence 1 based on if the data has VF active 
#this has coded the fence with a deactive VF to help capture the last paddock
#when no fence was active.
# but ..... there are logs on all days that have deactivated fences.
#not sure what to do about these - just remove them???

week1_2_3 <- week1_2_3 %>%  
  mutate(
    fencesID_1  = case_when(
      fencesID  == "19000" & group == "VF" ~ "fence1",
      fencesID  == "1922f" & group == "VF"~ "fence2",
      fencesID  == "11eab" & group == "VF"~ "fence3",
      group == "VF" & local_time >= ymd_hms("2020-11-03 11:57:00", tz= "Australia/Adelaide") ~ "deactive_VF3",
      group == "control" ~ "no_VF",
      TRUE        ~ "deactive_VF"))



# test <- week1_2_3 %>% dplyr::select(
#   fencesID ,
#   group,
#   Fence_code,
#   date,
#   fencesID_1,
#   week_numb,
#   local_time)
 

# check1 <- test %>% group_by( week_numb  , group, fencesID_1) %>% 
#   summarise(min_local_time = ymd_hms(min(local_time), tz= "Australia/Adelaide"),
#             max_local_time = ymd_hms(max(local_time), tz= "Australia/Adelaide"))
# 
# check1

check2 <- week1_2_3 %>% group_by( group, fencesID_1) %>% 
  summarise(min_local_time = ymd_hms(min(local_time), tz= "Australia/Adelaide"),
            max_local_time = ymd_hms(max(local_time), tz= "Australia/Adelaide"))

check2

 
```

## Activation of fences and subset the data into fences

- activation_fence1 2020-10-21 14:55:00
- activation_fence2 2020-10-25 10:50:00
- activation_fence3 2020-11-30 08:03:00
- *deactivation_fence4* 2020-10-03 11:56:00


There is a small discrepancy with the times (due to an approx. 10 min lag).



## Add columns to aid plotting and analysis.



Add extra one for days since fence move clm called 'day_since_vf_start'

Julian days from local date/time column and then subtract start of VF.

Note that for the last fence move 
I have used vf3_end "2020-11-03 11:57:00"

The dataset ends on the 09/11/2020

- Fence 1 ran for 5 days
- Fence 2 ran for 6 days 
- Fence 3 ran for 5 days
- Fence 3 was deactivated for 7 days (till the end of the trial)


### Table for chceking time of fence moves displayed with number of days since move

```{r add clms days since start, echo=FALSE, message=FALSE, warning=FALSE}



## clm for day of year in local time

vf1_start <-  yday(ymd_hms("2020-10-21 14:55:00", tz= "Australia/Adelaide")) 
vf2_start <-  yday(ymd_hms("2020-10-25 10:50:00", tz= "Australia/Adelaide"))
vf3_start <-  yday(ymd_hms("2020-10-30 08:03:00", tz= "Australia/Adelaide"))
vf3_end <-  yday(ymd_hms("2020-11-03 11:57:00", tz= "Australia/Adelaide"))



week1_2_3 <- week1_2_3 %>%  
  mutate(
    day_since_vf_start  = case_when(
      fencesID_1 == "fence1" ~ (DOY-vf1_start)+1,
      fencesID_1 == "fence2" ~ (DOY-vf2_start)+1,
      fencesID_1 == "fence3" ~ (DOY-vf3_start)+1,
      fencesID_1 == "deactive_VF3" ~ (DOY-vf3_end)+1))
  

check3 <- week1_2_3 %>% group_by( group, fencesID_1) %>% 
  summarise('min day since VF move' = min(day_since_vf_start),
            'max day since VF move' = max(day_since_vf_start))

check3



```

# Results for the paper

## Write up details 09-08-2021 and Dec 2021

### 1. Animal weights


At the end of the trial.

Weight gain expressed as:

- % gain clm M

- total gain (check the units ? grams) clm K

- Daily weight gain clm L

 W:/VF/LongPlain/Animal_ID/Long Plains animal weight pre post Nov 2020 collar correction done.xlsx




### mean daily weight gain

```{r mean daily weight gain, echo=FALSE, message=FALSE, warning=FALSE}

animal_wt <- read_excel("W:/VF/LongPlain/Animal_ID/Long Plains animal weight pre post Nov 2020 collar correction done.xlsx")

#str(animal_wt)
animal_wt <- dplyr::select(animal_wt,
                           `Mob Name`,
                           `Neckband Serial`,
                           `Animal Name`,
                           `Visual Tag ID`,
                           `NLIS ID`,
                           `Sex`,
                           `Breed`,
                           `% gain`,
                           'Weight gain',
                           Daily_weight_gain = `Daily weight gain  (18 days)`)


animal_wt <-   filter(animal_wt, !is.na (`Animal Name`))


mean_Daily_weight_gain <- animal_wt %>% 
  group_by(`Mob Name`)%>% 
  summarise(
    mean_daily_wt_gain = mean(Daily_weight_gain     , na.rm =TRUE),
    mean_daily_wt_gain_SD = sd(Daily_weight_gain,  na.rm = TRUE),
    mean_daily_wt_gain_SE = mean_daily_wt_gain_SD / sqrt(n()))
mean_Daily_weight_gain

```




### Animals weight gains stats

No significant weight gain differences between Mob


```{r animal wt gains  stats, echo=TRUE, message=FALSE, warning=FALSE}
# animal_wt 


#str(animal_wt)
animal_wts_aov <- aov(`Weight gain` ~ `Mob Name` , data = animal_wt)

summary(animal_wts_aov)


# total weight gain for mob
weight_gain <- animal_wt %>% 
  group_by(`Mob Name`) %>% 
  summarise(`total weight gain` = sum(`Weight gain`),
            `total weight gain SD` = sd(`Weight gain`,  na.rm = TRUE),
            `total weight gain SE` = `total weight gain SD` / sqrt(n()))


weight_gain

```



Dana / Caroline: We think body weight can just be reported in the text (no stats analyses, just the values). Mean (+SE) gain per group perhaps? Because we do only have the 1 vs 1 for our treatment/control, we don’t want to conclude too much. 

Jackie: total weight gain after 18 days measure in kg??? not on the data entry sheet

mean weight gain 

control = 25.7 SE 2.53
VF     =  22.4 SE 2.81

```{r write up body , echo=TRUE, message=FALSE, warning=FALSE}


body_wt_summary <- animal_wt %>% group_by(`Mob Name`) %>%
  summarise(
    Weight_gain_mean = mean(`Weight gain` ,  na.rm = TRUE),
    Weight_gain_SD = sd(`Weight gain`,  na.rm = TRUE),
    Weight_gain_SE = Weight_gain_SD / sqrt(
      n()),
      `% gain_mean` = mean(`% gain`,  na.rm = TRUE),
      percent_gain_SD = sd(`% gain`,  na.rm = TRUE),
      percent_gain_SE = percent_gain_SD / sqrt(n())
    )
body_wt_summary



```





#### 2. audio/pulse

Dana / Caroline: For the audio/pulse, we think just an average proportion in the text included SE would be sufficient rather than any graphs. Could this be the proportion of audio cues relative to total signals? We are anticipating it would be around 0.8. (No stats analyses, just the values)


prop audio total cues =
max_cumulativeAudioCount/(max_cumulativeShockCount + max_cumulativeAudioCount) *100

The below table is the mean of the proportion, audio and pluse and the standard error.

mean proportion of audio cues as a total of all cues  = 86% SE 1.02


  
```{r number of cues, message=FALSE, warning=FALSE, include=FALSE}

#1 create an ID for each row
#str(week1_2_3)

# just select the last day of the trial?

min(week1_2_3$local_time)
max_time_to_filter <- week1_2_3 %>%  group_by(deviceName, group) %>% 
  summarise(max_local_time = max(local_time, na.rm =TRUE))
#View(max_time_to_filter)
#count(max_time_to_filter)

max_time_to_filter2 <- max_time_to_filter %>%  group_by( group) %>% 
  summarise(min_max_time = min(max_local_time, na.rm =TRUE))
#View(max_time_to_filter2)




last_record <- week1_2_3 %>% 
  filter(between(ymd_hms(local_time),
                 ymd_hms("2020-11-09 08:57:00"), ymd_hms("2020-11-09 08:57:16"))) 

#View(last_record)
#Do we have one reading per animal? 
check <- last_record %>% group_by(deviceName) %>% 
  summarise(count = n())
#yes we have one reading per animal
#now do we have 40 animals?

check2 <- unique(check$deviceName)
#print(check2) # yes 40
#names(last_record)
last_record <- last_record %>% 
  dplyr::select(deviceUIDHex:timeOfEvent,cumulativeAudioCount, cumulativeShockCount, group, local_time, DOY )
#str(last_record)

last_record_summary <- last_record %>% 
  mutate(prop_audio_to_cues = cumulativeAudioCount/ (cumulativeShockCount + cumulativeAudioCount)*100)
#View(last_record_summary)

last_record_summary_stats <- last_record_summary %>% 
  group_by(group ) %>% 
  summarise(Av_Audio = mean(cumulativeAudioCount, na.rm = TRUE),
            std_dev_Av_Audio = sd(cumulativeAudioCount, na.rm = TRUE),
            SE_Av_Audio = std_dev_Av_Audio / sqrt(n()),
            
            Av_Pulse = mean(cumulativeShockCount, na.rm = TRUE),
            std_dev_Av_Pulse = sd(cumulativeShockCount, na.rm = TRUE),
            SE_Av_Pulse = std_dev_Av_Pulse / sqrt(n()),
            
            Av_prop = mean(prop_audio_to_cues, na.rm = TRUE),
            std_dev_prop = sd(prop_audio_to_cues, na.rm = TRUE),
            SE_Av_prop = std_dev_prop / sqrt(n()),
            
            count = n())

last_record_summary_stats

```
```{r number of cues table, echo=FALSE, message=FALSE, warning=FALSE}


 last_record_summary_stats %>% dplyr::select(group, `Av Audio` =Av_Audio, `SE Audio` = SE_Av_Audio,
                                             `Av Pulse` = Av_Pulse, `SE Pulse` = SE_Av_Pulse,
                                             `Av prop` = Av_prop, `SE prop` = SE_Av_prop, count) %>% 
  
  mutate(across(where(is.numeric), ~ round(., digits = 2))) %>% 
   formattable()


```






### 3. Behaviors

Dana / Caroline: We like the plot of grazing/resting/moving across all animals together (so not the individual animal plots). Probably no stats analyses because the unit is the group and we only have 1 group of each. But, could you include mean % values for each behavior (+SE) for the first 3 days for each group AND mean total values (+SE) for each group across the trial (just as values to include in the text). We would refer to it in
the discussion, we anticipate if there are substantial differences, it would be in the first few days. 


Jackie: 
- I have cal the average time spent resting, moving, grazing per animal per day (mean per animal per day).
- Then using this dataset I have cal the mean, sd ,se for each activity and group (the mean across all animals for whole trial).


I assume you still want VF and control mob plotted separately?
The three days are the 21-10 to 23-10.

```{r write up behaviours, message=FALSE, warning=FALSE, include=FALSE}


week1_2_3_animal_per_day_activity <- week1_2_3 %>% group_by(date, group, deviceName) %>% 
  summarise(av_resting = mean( resting., na.rm = TRUE),
            av_moving = mean( moving., na.rm = TRUE),
            av_grazing = mean( grazing., na.rm = TRUE))



week1_2_3_animal_per_day_activity <- pivot_longer(week1_2_3_animal_per_day_activity,
                                                  cols = c("av_resting", "av_moving", "av_grazing"),
                                                  names_to = "activity")






week1_2_3_activity <- week1_2_3_animal_per_day_activity %>% 
  group_by(activity, group)%>%
  summarise(activity_mean = mean(value, na.rm = TRUE),
            activity_SD =sd(value,  na.rm =TRUE),
            activity_SE=activity_SD/sqrt(n()))

week1_2_3_activity <- week1_2_3_activity %>% 
  mutate( activity = case_when(
    activity == "av_grazing" ~ "grazing",
    activity == "av_moving" ~ "moving",
    activity == "av_resting" ~ "resting"
  ))




week1_2_3_activity
#using summary data per animal per day per group per activity 
#"week1_2_3_animal_per_day_activity"
#I have extracting the first 3 days 
# Activation of VF 1 	2020-10-21 to the 	2020-10-23

week1_2_3_animal_per_day_activity <- ungroup(week1_2_3_animal_per_day_activity)
week1_2_3_animal_per_day_activity_3days <-
  week1_2_3_animal_per_day_activity %>% 
  filter(between(date, 
                 as.Date("2020-10-21"), as.Date("2020-10-23")))

min(week1_2_3_animal_per_day_activity_3days$date)                
max(week1_2_3_animal_per_day_activity_3days$date)               


str(week1_2_3_animal_per_day_activity_3days)
activity_sum_3days <- week1_2_3_animal_per_day_activity_3days %>% 
  group_by(activity, group)%>%
  summarise(activity_mean_3days = mean(value, na.rm = TRUE),
            activity_SD_3days =sd(value,  na.rm =TRUE),
            activity_SE_3days=activity_SD_3days/sqrt(n()))


activity_sum_3days <- activity_sum_3days %>% 
  mutate( activity = case_when(
    activity == "av_grazing" ~ "grazing 3days",
    activity == "av_moving" ~ "moving 3days",
    activity == "av_resting" ~ "resting 3days"
  ))
activity_sum_3days <- activity_sum_3days %>% 
  rename(activity_mean = activity_mean_3days,
         activity_SE = activity_SE_3days) %>% 
  dplyr::select(activity,
                group,
                activity_mean,
                activity_SE)

################################################################################
week1_2_3_animal_per_day_activity_3days_onwards <-
  week1_2_3_animal_per_day_activity %>% 
  filter(date > as.Date("2020-10-23"))
  # filter(between(date, 
  #                as.Date("2020-10-21"), as.Date("2020-10-23")))

min(week1_2_3_animal_per_day_activity_3days_onwards$date)                
max(week1_2_3_animal_per_day_activity_3days_onwards$date)               


str(week1_2_3_animal_per_day_activity_3days_onwards)
activity_sum_3days_onwards <- week1_2_3_animal_per_day_activity_3days_onwards %>% 
  group_by(activity, group)%>%
  summarise(activity_mean_3days_onwards = mean(value, na.rm = TRUE),
            activity_SD_3days_onwards =sd(value,  na.rm =TRUE),
            activity_SE_3days_onwards=activity_SD_3days_onwards/sqrt(n()))


activity_sum_3days_onwards <- activity_sum_3days_onwards %>% 
  mutate( activity = case_when(
    activity == "av_grazing" ~ "grazing excluding first 3days",
    activity == "av_moving" ~ "moving excluding first 3days",
    activity == "av_resting" ~ "resting excluding first 3days"
  ))
activity_sum_3days_onwards <- activity_sum_3days_onwards %>% 
  rename(activity_mean = activity_mean_3days_onwards,
         activity_SE = activity_SE_3days_onwards) %>% 
  dplyr::select(activity,
                group,
                activity_mean,
                activity_SE)

activity_sum_3days
activity_sum_3days_onwards

activity_summary <- rbind(activity_sum_3days,activity_sum_3days_onwards )
activity_summary
activity_summary <- activity_summary %>%  arrange(group, activity )

################# results

activity_summary <- activity_summary %>% 
  mutate(time_period = case_when(
    activity == "grazing excluding first 3days" ~ "full trial",
    activity == "moving excluding first 3days" ~ "full trial",
    activity == "resting excluding first 3days" ~ "full trial",
    
    activity == "grazing 3days" ~ "3 days",
    activity == "resting 3days" ~ "3 days",
    activity == "moving 3days" ~ "3 days"
  ))


activity_summary <- activity_summary %>% 
  mutate(activity_type = case_when(
    activity == "grazing excluding first 3days" ~ "grazing",
    activity == "moving excluding first 3days" ~ "moving",
    activity == "resting excluding first 3days" ~ "resting",
    
    activity == "grazing 3days" ~ "grazing",
    activity == "resting 3days" ~ "resting",
    activity == "moving 3days" ~ "moving"
  ))

activity_summary

activity_summary %>%
  filter(group == "VF") %>% 
  ggplot(aes(x = time_period , y = activity_mean, fill = time_period)) +
  geom_col()+
  scale_fill_manual(values = c("grey", "grey50"))+
  theme_classic() +
  facet_wrap(.~ factor(activity_type, levels=c('resting','grazing','moving')))+
  geom_errorbar(position=position_dodge(.9), width=.25, aes(ymin=activity_mean-activity_SE, ymax=activity_mean+activity_SE)) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x=element_blank())+
  labs(
    x = "VF Mob",
    y = "% time attributed to activity")


```


```{r write up behaviours results1, echo=FALSE, message=FALSE, warning=FALSE}



week1_2_3_activity <- week1_2_3_activity %>% 
  mutate(paddock = case_when(
    group == "control" ~ "open grazed",
    group == "VF" ~ "VF"
  ))

week1_2_3_activity %>%
  ggplot(aes(x = paddock , y = activity_mean, fill = paddock)) +
  geom_col()+
  scale_fill_manual(values = c("grey", "grey50"))+
  theme_classic() +
  facet_wrap(.~ factor(activity, levels=c('resting','grazing','moving')))+
  geom_errorbar(position=position_dodge(.9), width=.25, aes(ymin=activity_mean-activity_SE, ymax=activity_mean+activity_SE)) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x=element_blank())+
  labs(
    x = "Mob",
    y = "% time attributed to activity")
    


```



```{r write up behaviours results2, echo=FALSE, message=FALSE, warning=FALSE}
week1_2_3_activity %>% 
 mutate(across(where(is.numeric), ~ round(., digits = 2))) %>% 
   formattable()



```

#### Run an t-test on behaviours?

- Are open graze animals doing more resting than the VF animlas?
- Are open graze animals doing more grazing than the VF animlas?
- Are open graze animals doing more moving than the VF animlas?

http://www.sthda.com/english/articles/24-ggpubr-publication-ready-plots/76-add-p-values-and-significance-levels-to-ggplots/



```{r write up behaviours teste, echo=FALSE, message=FALSE, warning=FALSE}
#t test for different paddock


week1_2_3_animal_per_day_activity_test <- week1_2_3 %>% group_by(date, group, deviceName) %>% 
  summarise(av_resting = mean( resting., na.rm = TRUE),
            av_moving = mean( moving., na.rm = TRUE),
            av_grazing = mean( grazing., na.rm = TRUE))

week1_2_3_animal_per_day_activity_test <- week1_2_3_animal_per_day_activity_test %>% 
  mutate(paddock = case_when(
    group == "control" ~ "open grazed",
    group == "VF" ~ "VF"
  ))


week1_2_3_animal_per_day_activity_test <- ungroup(week1_2_3_animal_per_day_activity_test)


## resting
#t.test_resting <- t.test(av_resting ~ paddock, data = week1_2_3_animal_per_day_activity_test, paired = FALSE)
t.test_resting <-compare_means(av_resting ~ paddock,  data = week1_2_3_animal_per_day_activity_test, 
                               method = "t.test")

t.test_grazing <-compare_means(av_grazing ~ paddock,  data = week1_2_3_animal_per_day_activity_test, 
                               method = "t.test")
t.test_moving <-compare_means(av_moving ~ paddock,  data = week1_2_3_animal_per_day_activity_test, 
                               method = "t.test")


t_test_behaviour <- rbind(t.test_resting,t.test_grazing,t.test_moving)
#t_test_behaviour
t_test_behaviour %>% 
 #mutate(across(where(is.numeric), ~ round(., digits = 10))) %>% 
   formattable()

```


#### Behaviours on first 3 days vs the rest of the trial.

First three days are 21/10 to 23/10
Excluding the first three days are 24/10 to 09/11.

```{r write up behaviours test 3 days vs full trial, echo=FALSE, message=FALSE, warning=FALSE}
#Add another clm for time periods



activity_summary %>%
  filter(group == "VF") %>% 
  ggplot(aes(x = time_period , y = activity_mean, fill = time_period)) +
  geom_col()+
  scale_fill_manual(values = c("grey", "grey50"))+
  theme_classic() +
  facet_wrap(.~ factor(activity_type, levels=c('resting','grazing','moving')))+
  geom_errorbar(position=position_dodge(.9), width=.25, aes(ymin=activity_mean-activity_SE, ymax=activity_mean+activity_SE)) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x=element_blank())+
  labs(
    x = "VF Mob",
    y = "% time attributed to activity")
```


```{r write up behaviours test 3 days vs full trial t test, echo=FALSE, message=FALSE, warning=FALSE}

first_days_behaviour_test <- week1_2_3 %>% group_by(date, group, deviceName) %>% 
  summarise(av_resting = mean( resting., na.rm = TRUE),
            av_moving = mean( moving., na.rm = TRUE),
            av_grazing = mean( grazing., na.rm = TRUE))

first_days_behaviour_test <- first_days_behaviour_test %>% 
  mutate(paddock = case_when(
    group == "control" ~ "open grazed",
    group == "VF" ~ "VF"
  ))


first_days_behaviour_test <- ungroup(first_days_behaviour_test)
### split into two groups 
first_days_behaviour_test_1 <- first_days_behaviour_test %>% 
  filter(between(date, 
                 as.Date("2020-10-21"), as.Date("2020-10-23"))) %>% 
  mutate(time_period = "first_3_days")

first_days_behaviour_test_2 <- first_days_behaviour_test %>% 
  filter(date > as.Date("2020-10-23"))%>% 
  mutate(time_period = "exclude_first_3_days")

# min(first_days_behaviour_test_1$date)                
# max(first_days_behaviour_test_1$date)
# 
# min(first_days_behaviour_test_2$date)                
# max(first_days_behaviour_test_2$date)               

first_days_behaviour_test_1_2 <- rbind(first_days_behaviour_test_1,first_days_behaviour_test_2 )
#str(first_days_behaviour_test_1_2)
first_days_behaviour_test_1_2_VF <- first_days_behaviour_test_1_2 %>% 
  filter(paddock == "VF")

## resting for on VF

t.test_resting_first_days <-compare_means(av_resting ~ time_period,  data = first_days_behaviour_test_1_2_VF, 
                               method = "t.test")

t.test_grazing_first_days <-compare_means(av_grazing ~ time_period,  data = first_days_behaviour_test_1_2_VF, 
                               method = "t.test")
t.test_moving_first_days <-compare_means(av_moving ~ time_period,  data = first_days_behaviour_test_1_2_VF, 
                              method = "t.test")


t_test_behaviour_first_days <- rbind(t.test_resting_first_days,t.test_grazing_first_days,t.test_moving_first_days)
#t_test_behaviour
t_test_behaviour_first_days %>% 
  #mutate(across(where(is.numeric), ~ round(., digits = 10))) %>% 
  formattable()

```










### 4. GPS plots

Dana / Caroline: For GPS Plots. Could you plot the movement of each group on the first day of fence activation/deactivation. 

These would be plots similar to the ones you have done ‘Days since start of VF’ in the document but would only include day 1 of each activation/deactivation and would have the control group plotted simultaneously. 

Thus, 4 paddock map plots in total. (Let me know if that is unclear and/or if Rick has something different in mind). 

Is it also possible to calculate the time from fence change until the first animal entered the new, previously excluded area? 

That way we could state ‘on average, once a fence had shifted position/was deactivated, it took the animals 2 (?) hours to move into the new area’. 



```{r write up GPS plots workings, message=FALSE, warning=FALSE, include=FALSE}

#need to make df into spatial object for graphing and try clipping to paddock boundary
long_plains <- st_read("W:/VF/LongPlain/LP Blk Bound/LongPlain_GDA_internal_bound.shp")
long_plains_Vf <- st_read("W:/VF/LongPlain/LP Blk Bound/LongPlainVF_bound.shp")
long_plains_Vf_area <- st_read("W:/VF/LongPlain/LP Blk Bound/LongPlainVF_area_bound.shp")

#str(week1_2_3)


week1_2_3_sf <-
      st_as_sf(week1_2_3,
               coords = c("gpsData.lng", "gpsData.lat"),
               crs = 4326,
               agr = "constant")

week1_2_3_sf_trans <-
      st_transform(week1_2_3_sf, crs = 28354)
week1_2_3_sf_clip <-
      st_intersection(week1_2_3_sf_trans, long_plains)
    

fence1_GPS <- week1_2_3_sf_clip %>% 
  filter(fencesID_1 == "fence1")  
fence2_GPS <- week1_2_3_sf_clip %>% 
  filter(fencesID_1 == "fence2")
fence3_GPS <- week1_2_3_sf_clip %>% 
  filter(fencesID_1 == "fence3") 
fence3_deactive_GPS <- week1_2_3_sf_clip %>% 
  filter(fencesID_1 == "deactive_VF3") 



# pull out day 1 for each VF for the vf mob note that some clipping has been done.

fence1_day1 <-filter(fence1_GPS, day_since_vf_start == 1)
fence2_day1 <-filter(fence2_GPS, day_since_vf_start == 1)
fence3_day1 <-filter(fence3_GPS, day_since_vf_start == 1)
fence3_deactivated_day1 <-filter(fence3_deactive_GPS, day_since_vf_start == 1)



## just want the first 8 hours from each fence change
min(fence1_day1$local_time)+hours(8)
fence1_day1 <- fence1_day1 %>% filter(local_time <= ymd_hms("2020-10-21 23:07:00", tz= "Australia/Adelaide"))

min(fence2_day1$local_time)+hours(8)
fence2_day1 <- fence2_day1 %>% filter(local_time <= ymd_hms("2020-10-25 18:57:00", tz= "Australia/Adelaide"))

min(fence3_day1$local_time)+hours(8)
fence3_day1 <- fence3_day1 %>% filter(local_time <= ymd_hms("2020-10-30 16:07:00", tz= "Australia/Adelaide"))
               
min(fence3_deactivated_day1$local_time)+hours(8)
fence3_deactivated_day1 <- fence3_deactivated_day1 %>% 
  filter(local_time <= ymd_hms("2020-11-03 20:07:00", tz= "Australia/Adelaide"))



fence1_3_deactice3_day1 <- rbind(fence1_day1, fence2_day1,fence3_day1, fence3_deactivated_day1 )

fence1_day1 <-  fence1_day1 %>% 
  mutate(day_since_trial_start = 1)

fence2_day1 <-  fence2_day1 %>% 
  mutate(day_since_trial_start = 5)

fence3_day1 <-  fence1_day1 %>% 
  mutate(day_since_trial_start = 10)

fence3_deactivated_day1 <-  fence1_day1 %>% 
  mutate(day_since_trial_start = 14)

fence1_3_deactice3_day1 <-  fence1_3_deactice3_day1 %>% 
  mutate(day_since_trial_start = case_when(
    date == "2020-10-21" ~ 1,
    date == "2020-10-25" ~ 5,
    date == "2020-10-30" ~ 10,
    date == "2020-11-03" ~ 14
  ))

# get the control mob only


week1_2_3_sf_clip_control <- week1_2_3_sf_clip %>% 
  filter(VF_name == "Control")

#What are the dates for day 1 with the VF mob use these dates to filter the control mob
#unique(fence1_3_deactice3_day1$date)


#list_of_date <- list(unique(fence1_3_deactice3_day1$date)) #I dont know why this wont work??
#test <- week1_2_3_sf_clip_control %>% filter(date  %in% list_of_date)

week1_2_3_sf_clip_control_day1 <- week1_2_3_sf_clip_control %>% filter(date  == "2020-10-21" |
                                             date  == "2020-10-25" |
                                             date  == "2020-10-30" |
                                             date  == "2020-11-03")

week1_2_3_sf_clip_control_day1 <- week1_2_3_sf_clip_control_day1 %>% 
  mutate(day_since_trial_start = case_when(
    date == "2020-10-21" ~ 1,
    date == "2020-10-25" ~ 5,
    date == "2020-10-30" ~ 10,
    date == "2020-11-03" ~ 14
  ))

```

#### Animal movement day 1 of each fence move for 8 hours

```{r write up GPS plots image, echo=TRUE, message=FALSE, warning=FALSE}
long_plains_Vf_area <- long_plains_Vf_area %>% 
  mutate(day_since_trial_start = case_when(
    VF_Agersen == "VF1" ~ 1,
    VF_Agersen == "VF1 and 2" ~ 5,
    VF_Agersen == "VF 1, 2 and 3" ~ 10,
    VF_Agersen == "VF 1, 2, 3 and 4" ~ 14
  ))

ggplot() +
  geom_sf(data = long_plains, color = "black", fill = NA) +
  geom_sf(data = long_plains_Vf_area, color = "black", fill = NA) +
  geom_sf(data = fence1_3_deactice3_day1 ,alpha = 0.01) +
  geom_sf(data = week1_2_3_sf_clip_control_day1 ,colour = "skyblue4", alpha = 0.01) +
  theme_bw()+
  theme(legend.position = "none",
        axis.ticks = element_blank(), axis.text.x = element_blank(), axis.text.y = element_blank())+
  #labs(title= "Day1 of VF")+
  facet_wrap(.~ day_since_trial_start)

```



For each above plot Dana would like to know how what is the time window.

```{r write up GPS plots time period, echo=TRUE, message=FALSE, warning=FALSE}
fence1_3_deactice3_day1_time <- fence1_3_deactice3_day1 %>%
  dplyr::select(fencesID_1,local_time ) %>% 
  group_by(fencesID_1) %>% 
  summarise(min_local_time = min(local_time),
            max_local_time = max(local_time))


fence1_3_deactice3_day1_time <- as.data.frame(fence1_3_deactice3_day1_time)

fence1_3_deactice3_day1_time <- as.data.frame(fence1_3_deactice3_day1_time)
fence1_3_deactice3_day1_time <-fence1_3_deactice3_day1_time %>% dplyr::select(fencesID_1,min_local_time, max_local_time )  %>% 
  arrange(min_local_time)



fence1_3_deactice3_day1_time <- fence1_3_deactice3_day1_time %>% 
  mutate(difference_in_time = max_local_time - min_local_time)
         
fence1_3_deactice3_day1_time

```

Is it also possible to calculate the time from fence change until the first animal entered the new, previously excluded area?

Yeah this should be easy!
A couple of thing make it more challenging:

1. The area "VF 4" the very far west of the paddock has no VF active.

2. Agersens collect data normally in 10 min intervals.

3. the GPS is data is a snap shot of where the animal is in this 10 min window.

4. Tanusri has suggested:
If the values in “fenceID” column as blank, this means there is no active virtual fence for that neckband yet. Therefore, if you are performing some analysis related to virtual fencing, you can ignore those rows with blank fenceIDs." This makes it difficult to use the data for VF area 4.

5. There is a lag between when the fence is moved approx 10mins

There are a couple of ways to do this and nothing is perfect.
I have worked out when the VF has become active and for fence 3 when it is active and deactivate. 
Using this date time pulled out a window of time close to the fence move.
Then I have selected data in the new VF area only and reported the smallest time value.

- VF Fence 2 -25th

From activation to animals moving to new VF area (VF2 area) took approx 6hrs

- VF Fence 3 - 30th

From activation to animals moving to new VF area (VF3 area) took approx 15 sec
This doesn't seem correct.
I tried a different approach and got the same ans
When you look at the plots it appears an animals was already there!

- Deactivation VF Fence 3 - 3rd
From deactivation to animals moving to new VF area (VF4 area) took approx 7 hours


Jackie: heaps of plots not displayed (code is still in document).

```{r write up GPS plots first animal  25th, message=FALSE, warning=FALSE, include=FALSE}

# a. Filter VF mob GPS data for the 25th only (but use the clipped dataset week1_2_3_sf_trans)
# b. clip 25VFmob to new VF boundary (long_plains_Vf2) 25VFmob_VF2 
# c. Filter 25VFmob_VF2 to the agensen fence code 1922f 25VFmob_VF2_1922f
# d. report the min local time 25VFmob_VF2_1922f o.

##########################################################################################################
#Is it also possible to calculate the time from fence change until the first animal entered the new, previously excluded area?

#Activation of VF 2 occured at 2020-10-25 10:50 (dont forget that sometime there is a lag)
#a. Filter VF mob GPS data for the 25th only (but use the clipped dataset week1_2_3)
#b. clip 25VFmob to new VF boundary 25VFmob_VF2
#c. Arrange 25VFmob_VF2 on time.
######################################################################################################################
long_plains_Vf2 <- long_plains_Vf %>% 
  filter(VF_Agersen == "VF2") 
long_plains_Vf1 <- long_plains_Vf %>% 
  filter(VF_Agersen == "VF1")
long_plains_Vf3 <- long_plains_Vf %>% 
  filter(VF_Agersen == "VF3") 
long_plains_Vf4 <- long_plains_Vf %>% 
  filter(VF_Agersen == "VF4") 

week1_2_3_select_date <- week1_2_3_sf_trans %>% filter(date  == "2020-10-21" |
                                                date  == "2020-10-25" |
                                                date  == "2020-10-30" |
                                                date  == "2020-11-03")

week1_2_3_select_date <- week1_2_3_select_date %>%  filter(group == "VF")
######################################################################################################################
## select date 
VFmob25 <- week1_2_3_select_date %>% 
  filter(date == "2020-10-25")
#check that its sensible
VFmob25 %>% group_by() %>% 
  summarise(min_local_time =    min(local_time,na.rm = TRUE))#this is just a chcek


#clip my selected date VF mob data to the new paddock area
VFmob25_clip_VF2 <-  st_intersection(VFmob25, long_plains_Vf2)

#This VF mob on the 25th that are only in the VF2 location we have some GPS logs that exist on the 25th but when fence 1 was active
# Using Fence_code clm 

# agersens assigned a code in Fence_code clm for data enteries that relate to this fence
VFmob25_clip_VF2_1922f <- VFmob25_clip_VF2 %>% 
  filter(Fence_code=="1922f")


##########################################################################################################################
### when did fence 1922f become active?
## check what was the min time when Fence_code 1922f existed
week1_2_3_sf_trans_1922f <-
  week1_2_3_sf_trans %>% filter(Fence_code == "1922f")

min_time_fence_1922f <- week1_2_3_sf_trans_1922f %>% group_by() %>%
  summarise(min_local_time =    min(local_time, na.rm = TRUE)
  )
### when did the first data enetry occur after fence 1922f become active on the 25th and in the VF 2 area?
min_time_fence_1922f_move <- VFmob25_clip_VF2_1922f %>% group_by() %>% 
  summarise(min_local_time =    min(local_time,na.rm = TRUE)
   )

##########################################################################################################################

min_time_fence_1922f_df <- st_set_geometry(min_time_fence_1922f, NULL)
min_time_fence_1922f_move_df <- st_set_geometry(min_time_fence_1922f_move, NULL)
min_time_fence_1922f_merge <- rbind(min_time_fence_1922f_df,min_time_fence_1922f_move_df)

fence_details <- c("fence_1922f", "fence_1922f_animal_move")
animal_move_25 <- data.frame(fence_details, min_time_fence_1922f_merge) 



######################################################################################################################
## select date next fence
VFmob30 <- week1_2_3_select_date %>% 
  filter(date == "2020-10-30")
#check that its sensible
VFmob30 %>% group_by() %>% 
  summarise(min_local_time =    min(local_time,na.rm = TRUE))#this is just a chcek


#clip my selected date VF mob data to the new paddock area
VFmob30_clip_VF3 <-  st_intersection(VFmob30, long_plains_Vf3)


#This VF mob on the 30th that are only in the VF3 location we have some GPS logs that exist on the 30th but when fence 2 was active
# Using Fence_code clm 

# agersens assigned a code in Fence_code clm for data enteries that relate to this fence
VFmob30_clip_VF3_11eab <- VFmob30_clip_VF3 %>% 
  filter(Fence_code=="11eab")


##########################################################################################################################
### when did fence 11eab become active?
## check what was the min time when Fence_code 1922f existed
week1_2_3_sf_trans_11eab <-
  week1_2_3_sf_trans %>% filter(Fence_code == "11eab")


min_time_fence_11eab <- week1_2_3_sf_trans_11eab %>% group_by() %>%
  summarise(min_local_time =  min(local_time, na.rm = TRUE))


### when did the first data enetry occur after fence 1922f become active on the 25th and in the VF 2 area?
min_time_fence_11eab_move <- VFmob30_clip_VF3_11eab %>% group_by() %>% 
  summarise(min_local_time =    min(local_time,na.rm = TRUE)
  )

##########################################################################################################################

min_time_fence_11eab_df <- st_set_geometry(min_time_fence_11eab, NULL)
min_time_fence_11eab_move_df <- st_set_geometry(min_time_fence_11eab_move, NULL)
min_time_fence_11eab_merge <- rbind(min_time_fence_11eab_df,min_time_fence_11eab_move_df)

fence_details_11eab <- c("fence_11eab", "fence_11eab_animal_move")
animal_move_30 <- data.frame(fence_details_11eab, min_time_fence_11eab_merge) 


##########################################################################################################################
### put these two togther

animal_move_30 <- animal_move_30 %>%  dplyr::rename("fence_details" = "fence_details_11eab")

animal_move_25_30 <- rbind(animal_move_25, animal_move_30)

##########################################################################################################################

######################################################################################################################
## select date next fence
VFmob03 <- week1_2_3_select_date %>% 
  filter(date == "2020-11-03")
#check that its sensible
VFmob03 %>% group_by() %>% 
  summarise(min_local_time =    min(local_time,na.rm = TRUE))#this is just a chcek


#clip my selected date VF mob data to the new paddock area
VFmob03_clip_VF4 <-  st_intersection(VFmob03, long_plains_Vf4)


#This VF mob on the 30th that are only in the VF3 location we have some GPS logs that exist on the 30th but when fence 2 was active
# Using Fence_code clm 

# agersens assigned a code in Fence_code clm for data enteries that relate to this fence - now there is no fence?
# I can remove entries that have other fence codes 
VFmob03_clip_VF4_xxx <- VFmob03_clip_VF4 %>% 
  filter(Fence_code !="11eab" &Fence_code !="19000" &Fence_code !="1922f")


##########################################################################################################################
### when did fence 11eab become DE active?
## check what was the min time when Fence_code 1922f existed
week1_2_3_sf_trans_xxx <-
  week1_2_3_sf_trans %>% filter(Fence_code !="11eab" & 
                                  Fence_code !="19000" & 
                                  Fence_code !="1922f" &
                                  date == "2020-11-03")


min_time_fence_xxx <- week1_2_3_sf_trans_xxx %>% group_by() %>%
  summarise(min_local_time =  min(local_time, na.rm = TRUE))


### when did the first data enetry occur after fence 1922f become active on the 25th and in the VF 2 area?
min_time_fence_xxx_move <- VFmob03_clip_VF4_xxx %>% group_by() %>% 
  summarise(min_local_time =    min(local_time,na.rm = TRUE)
  )
##########################################################################################################################

min_time_fence_xxx_df <- st_set_geometry(min_time_fence_xxx, NULL)
min_time_fence_xxx_move_df <- st_set_geometry(min_time_fence_xxx_move, NULL)
min_time_fence_xxx_merge <- rbind(min_time_fence_xxx_df,min_time_fence_xxx_move_df)

fence_details_xxx <- c("fence_xxx", "fence_xxx_animal_move")
animal_move_03 <- data.frame(fence_details_xxx, min_time_fence_xxx_merge) 


##########################################################################################################################
animal_move_03 <- animal_move_03 %>%  dplyr::rename("fence_details" = "fence_details_xxx")

animal_move_25_30_03 <- rbind(animal_move_25_30, animal_move_03)







```




```{r write up GPS plots first animal different approach, message=FALSE, warning=FALSE, include=FALSE}
##################################################################################
##define the VF area
long_plains_Vf2 <- long_plains_Vf %>% 
  filter(VF_Agersen == "VF2") 
long_plains_Vf1 <- long_plains_Vf %>% 
  filter(VF_Agersen == "VF1")
long_plains_Vf3 <- long_plains_Vf %>% 
  filter(VF_Agersen == "VF3") 
long_plains_Vf4 <- long_plains_Vf %>% 
  filter(VF_Agersen == "VF4") 
##################################################################################

## week 3 import raw data and format

csiro_week3exports_ending_2020_11_09 <- read.csv("W:/VF/LongPlain/Collar_data/csiro_weeklyexports_ending_2020-11-09.csv")

csiro_week3exports_ending_2020_11_09 <- csiro_week3exports_ending_2020_11_09 %>% 
  mutate(GMT = ymd_hms(timeOfEvent, tz = "GMT"),
         group = "VF")
csiro_week3exports_ending_2020_11_09 <- csiro_week3exports_ending_2020_11_09 %>% 
  mutate(local_time = with_tz(GMT, tz = "Australia/Adelaide"))

week3<- csiro_week3exports_ending_2020_11_09 %>% 
  mutate(date = as.Date(local_time, tz= "Australia/Adelaide"),
       DOY = yday(date))

week3 <- week3 %>%  filter(local_time >= ymd_hms("2020-10-21 15:07:00", tz= "Australia/Adelaide"), 
                                   local_time <=  ymd_hms("2020-11-09 09:00:00", tz= "Australia/Adelaide"))

week3_sf <-
  st_as_sf(week3,
           coords = c("gpsData.lng", "gpsData.lat"),
           crs = 4326,
           agr = "constant")

week3_sf_trans <-
  st_transform(week3_sf, crs = 28354)

#######################################################################################################################
# Use raw data and select a window that is close to the fence moving

week3_11eab_only <- week3_sf_trans %>% filter(fencesID =="11eab")
max_time_11eab <- week3_11eab_only %>% group_by() %>%
  summarise(max_local_time =  max(local_time, na.rm = TRUE))                                                        
max_time_11eab # 2020-11-03 11:57:16 
fence_3_deactiveated <- max_time_11eab


window_deactive <- week3_sf_trans %>% 
  filter(between(ymd_hms(local_time), 
                 ymd_hms("2020-11-03 11:40:00"), ymd_hms("2020-11-03 16:40:00"))) 

#this is VF mob 5 hour after fence has been deactivated
#clip my selected date VF mob data to the new paddock area
deactive_window_clip_VF4 <-  st_intersection(window_deactive, long_plains_Vf4)
deactive_window_clip_VF1_4 <- st_intersection(window_deactive, long_plains_Vf)

#check that its sensible
fence_3_deactiveated_move <- deactive_window_clip_VF4 %>% group_by() %>% 
  summarise(min_local_time =    min(local_time,na.rm = TRUE))#this is just a chcek


fence_3_deactiveated_move <- st_set_geometry(fence_3_deactiveated_move, NULL)
fence_3_deactiveated <- st_set_geometry(fence_3_deactiveated, NULL)
fence_3_deactiveated_move #(min_local_time)
fence_3_deactiveated #max_local_time
fence_3_deactiveated <- fence_3_deactiveated %>%  
  dplyr::rename("local_time" = "max_local_time")
fence_3_deactiveated_move <- fence_3_deactiveated_move %>%  
  dplyr::rename("local_time" = "min_local_time")

fence_deactivated <- rbind(fence_3_deactiveated, fence_3_deactiveated_move)

fence_details_xxx <- c("fence_deactivate", "fence_deactivate_animal_move")
animal_move_03 <- data.frame(fence_details_xxx, fence_deactivated) 
animal_move_03 <- animal_move_03 %>%  dplyr::rename("fence_details" = "fence_details_xxx")
animal_move_03






  
##################################################################################################################
## week 1 import raw data and format

csiro_weeklyexports_ending_2020_10_26 <- read.csv("C:/Users/ouz001/working_from_home/VF_Long_plain/logged_cattle/csiro_weeklyexports_ending_2020-10-26.csv")
csiro_weeklyexports_ending_2020_10_26 <- csiro_weeklyexports_ending_2020_10_26 %>% 
  mutate(GMT = ymd_hms(timeOfEvent, tz = "GMT"),
         group = "VF")
csiro_weeklyexports_ending_2020_10_26 <- csiro_weeklyexports_ending_2020_10_26 %>% 
  mutate(local_time = with_tz(GMT, tz = "Australia/Adelaide"))
week1<- csiro_weeklyexports_ending_2020_10_26 %>% 
  mutate(date = as.Date(local_time, tz= "Australia/Adelaide"),
         DOY = yday(date))

week1 <- week1 %>%  filter(local_time >= ymd_hms("2020-10-21 15:07:00", tz= "Australia/Adelaide"), 
                           local_time <=  ymd_hms("2020-11-09 09:00:00", tz= "Australia/Adelaide"))

week1_sf <-
  st_as_sf(week1,
           coords = c("gpsData.lng", "gpsData.lat"),
           crs = 4326,
           agr = "constant")
week1_sf_trans <-
  st_transform(week1_sf, crs = 28354)

 
#######################################################################################
week1_1922f_only <- week1_sf_trans %>% filter(fencesID =="1922f")
min_time_1922f <- week1_1922f_only %>% group_by() %>%
  summarise(min_local_time =  min(local_time, na.rm = TRUE))                                                        
min_time_1922f # 2020-10-25 10:57:00 # I am happy with this 
fence_2_activated <- min_time_1922f


window_active1922f <- week1_sf_trans %>% 
  filter(between(ymd_hms(local_time), ymd_hms("2020-10-25 10:57:00"), ymd_hms("2020-10-25 18:57:00"))) 

#this is VF mob 5 hour after fence has been deactivated
#clip my selected date VF mob data to the new paddock area
active1922F_window_clip_VF2 <-  st_intersection(window_active1922f, long_plains_Vf2)

#check that its sensible
fence_2_active_move <- active1922F_window_clip_VF2 %>% group_by() %>% 
  summarise(min_local_time = min(local_time,na.rm = TRUE))#this is just a chcek
fence_2_active_move

fence_2_active_move <- st_set_geometry(fence_2_active_move, NULL)
fence_2_activated <- st_set_geometry(fence_2_activated, NULL)

fence_2_active <- rbind(fence_2_activated, fence_2_active_move)

fence2_details <- c("fence_activated", "fence_activate_animal_move")
animal_move_25 <- data.frame(fence2_details, fence_2_active) 
animal_move_25 <- animal_move_25 %>%  dplyr::rename("fence_details" = "fence2_details",
                                                    "local_time" = "min_local_time")

animal_move_25_03 <- rbind(animal_move_25, animal_move_03)
animal_move_25_03



#####################################################################################################################
csiro_week2exports_ending_2020_11_02 <- read.csv("W:/VF/LongPlain/Collar_data/csiro_weeklyexports_ending_2020-11-02.csv")
csiro_week2exports_ending_2020_11_02 <- csiro_week2exports_ending_2020_11_02 %>% 
  mutate(GMT = ymd_hms(timeOfEvent, tz = "GMT"),
         group = "VF")
csiro_week2exports_ending_2020_11_02 <- csiro_week2exports_ending_2020_11_02 %>% 
  mutate(local_time = with_tz(GMT, tz = "Australia/Adelaide"))
week2<- csiro_week2exports_ending_2020_11_02 %>% 
  mutate(date = as.Date(local_time, tz= "Australia/Adelaide"),
         DOY = yday(date))
week2 <- week2 %>%  filter(local_time >= ymd_hms("2020-10-21 15:07:00", tz= "Australia/Adelaide"), 
                           local_time <=  ymd_hms("2020-11-09 09:00:00", tz= "Australia/Adelaide"))
week2_sf <-
  st_as_sf(week2,
           coords = c("gpsData.lng", "gpsData.lat"),
           crs = 4326,
           agr = "constant")
week2_sf_trans <-
  st_transform(week2_sf, crs = 28354)

#######################################################################################
week2_11eab_only <- week2_sf_trans %>% filter(fencesID =="11eab")
min_time_11aeb <- week2_11eab_only %>% group_by() %>%
  summarise(min_local_time =  min(local_time, na.rm = TRUE))                                                        
min_time_11aeb #  2020-10-30 08:07:00 # I am happy with this 
fence_3_activated <- min_time_11aeb
fence_3_activated

window_active11eab <- week2_sf_trans %>% 
  filter(between(ymd_hms(local_time), ymd_hms("2020-10-30 08:07:00"), ymd_hms("2020-10-30 08:50:00"))) 

#this is VF mob 5 hour after fence has been deactivated
#clip my selected date VF mob data to the new paddock area
active11eab_window_clip_VF3 <-  st_intersection(window_active11eab, long_plains_Vf3)
#View(active11eab_window_clip_VF3)

#check that its sensible
fence_3_active_move <- active11eab_window_clip_VF3 %>% group_by() %>% 
  summarise(min_local_time = min(local_time,na.rm = TRUE))#this is just a chcek
fence_3_active_move
fence_3_active_move <- st_set_geometry(fence_3_active_move, NULL)
fence_3_activated <- st_set_geometry(fence_3_activated, NULL)
fence_3_active <- rbind(fence_3_activated, fence_3_active_move)

fence3_details <- c("fence_activated", "fence_activate_animal_move")
animal_move_30 <- data.frame(fence3_details, fence_3_active) 
animal_move_30 <- animal_move_30 %>%  dplyr::rename("fence_details" = "fence3_details",
                                                    "local_time" = "min_local_time")

animal_move_25_03_30 <- rbind(animal_move_25_03, animal_move_30)








```

```{r write up GPS plots first animal  results, message=FALSE, warning=FALSE, include=FALSE}
#Summary of times animals move into new grazing area

animal_move_25_03_30

#Plot all data / animals in window - facet is the hours
deactive_window_clip_VF1_4 <- deactive_window_clip_VF1_4 %>% 
  mutate(time = hms::as_hms(local_time),
         hours = substr(time, 1, 2))  

ggplot() +
  geom_sf(data = long_plains, color = "black", fill = NA) +
  geom_sf(data = long_plains_Vf, color = "black", fill = NA) +
  geom_sf(data = deactive_window_clip_VF1_4 ,colour = "skyblue4", alpha = 1) +
  theme_bw()+
  theme(legend.position = "none",
        axis.ticks = element_blank(), axis.text.x = element_blank(), axis.text.y = element_blank())+
  labs(title= "deactivation of fence 3 2020-11-03 11:56:00",
       subtitle = "facet wrap is every hour" )+
  facet_wrap(.~ hours)

#####################################################################################
#Plot all data / animals in window - facet is the hours
window_active1922f <- window_active1922f %>% 
  mutate(time = hms::as_hms(local_time),
         hours = substr(time, 1, 2))  

ggplot() +
  geom_sf(data = long_plains, color = "black", fill = NA) +
  geom_sf(data = long_plains_Vf, color = "black", fill = NA) +
  geom_sf(data = window_active1922f ,colour = "skyblue4", alpha = 1) +
  theme_bw()+
  theme(legend.position = "none",
        axis.ticks = element_blank(), axis.text.x = element_blank(), axis.text.y = element_blank())+
  labs(title= "Activation of fence 2 2020-10-25 10:57:00",
       subtitle = "facet wrap is every hour" )+
  facet_wrap(.~ hours)
#####################################################################################
#Plot all data / animals in window - facet is the hours
window_active11eab <- window_active11eab %>%
  mutate(time = hms::as_hms(local_time),
         hours = substr(time, 1, 2),
         mins = substr(time, 4, 5),
         min_round_10mins = plyr::round_any(as.double(mins), 10))

#library(hms) Add these before I use them?
#library(plyr)

ggplot() +
  geom_sf(data = long_plains, color = "black", fill = NA) +
  geom_sf(data = long_plains_Vf, color = "black", fill = NA) +
  geom_sf(data = long_plains_Vf3, color = "green", fill =NA) +
  geom_sf(data = window_active11eab ,colour = "skyblue4", alpha = 1) +
  theme_bw()+
  theme(legend.position = "none",
        axis.ticks = element_blank(), axis.text.x = element_blank(), axis.text.y = element_blank())+
  labs(title= "Activation of fence 3 2020-10-30 08:07:00",
       subtitle = "facet wrap is every 10 min from 08:10 to 8:50" )+
  facet_wrap(.~ min_round_10mins)

```


```{r write up GPS plots first animal  results table, echo=FALSE, message=FALSE, warning=FALSE}

animal_move_25_03_30 <- animal_move_25_03_30 %>% mutate(VF = case_when(
  local_time == "2020-10-25 10:57:00" ~ "VF2",
  local_time == "2020-10-25 16:27:00" ~ "VF2",
  
  local_time == "2020-10-30 08:07:00" ~ "VF3",
  local_time == "2020-10-30 08:07:15" ~ "VF3",
  
  local_time == "2020-11-03 11:57:16" ~ "VF4",
  local_time == "2020-11-03 16:07:01" ~ "VF4",
  
))

animal_move_25_03_30 <- animal_move_25_03_30 %>% mutate(start_animal = case_when(
  local_time == "2020-10-25 10:57:00" ~ "start",
  local_time == "2020-10-25 16:27:00" ~ "animal_entered",
  
  local_time == "2020-10-30 08:07:00" ~ "start",
  local_time == "2020-10-30 08:07:15" ~ "animal_entered",
  
  local_time == "2020-11-03 11:57:16" ~ "start",
  local_time == "2020-11-03 16:07:01" ~ "animal_entered",
  
))


animal_move_25_03_30_wide <- animal_move_25_03_30 %>% 
  pivot_wider(names_from = start_animal, 
              values_from = local_time)

animal_move_25_03_30_wide <- animal_move_25_03_30_wide %>% 
  fill(start )%>% 
  filter(!is.na(animal_entered)) %>% 
  dplyr::select(VF, start, animal_entered) %>% 
  mutate(time_entered_hours = animal_entered - start) %>% 
  arrange(start)
   
animal_move_25_03_30_wide$time_entered_hours <- as.numeric(animal_move_25_03_30_wide$time_entered_hours, units = "hours")

animal_move_25_03_30_wide 
```

#### 4. Resting Plots

Dana / Caroline: Only additional analysis we thought could be interesting would be to plot where the animals rest in the paddock. 

Since resting is stationary, the intermittent GPS sampling should be less of an issue. 

We were interested if the changing fences had any impact on where the animals preferred to rest relative to the control . 

I.e. did their resting spot change as the paddock inclusion area got larger in the VF group? 

We think this would be interesting and new from our perspective, but if it is going to be days and days to get that analysis done then it probably is not worth the time. 

Jackie: One approach would be to produce a heat map of where the animals rested.
1.extract all of the resting data from the dataset.
2. create a new dataset which has a regular time interval (not sure how frequent this would be perhaps every 15mins?)
2.plot this onto a grid and count the observation in the grid for all animals in the mob on each day.

```{r write resting spots working, message=FALSE, warning=FALSE, include=FALSE}


#good place to start would be  

write.csv(week1_2_3, "W:/VF/LongPlain/R_scripts_etc/VF_LP/resting_spots_for_paper/week1_2_3_start.csv")
```

```{r write up resting spots working_version1, message=FALSE, warning=FALSE, include=FALSE}

#step1 one pull out the all the resting data only.

week1_2_3 <- read_csv("W:/VF/LongPlain/R_scripts_etc/VF_LP/resting_spots_for_paper/week1_2_3_start.csv", 
         col_types = cols(GMT = col_datetime(format = "%Y-%m-%d %H:%M:%S"), 
                          date = col_date(format = "%Y-%m-%d"), 
                          local_time = col_datetime(format = "%Y-%m-%d %H:%M:%S"), 
                          timeOfEvent = col_datetime(format = "%Y-%m-%d %H:%M:%S")))
week1_2_3 <- week1_2_3 %>%
  mutate(time = hms::as_hms(local_time))
#only select the resting data
week1_2_3_rest <- week1_2_3 %>%  filter(!is.na(week1_2_3$resting.))
week1_2_3_rest <- week1_2_3 %>%  filter(group == "VF" )

week1_2_3_rest <- week1_2_3_rest %>%
  dplyr::select(
    deviceName,
    gpsData.lat,
    gpsData.lng,
    fencesID,
    fencesID_1,
    resting = resting.,
    local_time,
    date,
    day_since_vf_start,
    time
  )
# ## work with a small subset of data one animal one day.
# rest_2020_10_21_9370004 <- week1_2_3_rest %>%
#   filter(date == "2020-10-21" & deviceName == "9370004") %>% 
#   arrange(local_time)

#change the local time to correct format
week1_2_3_rest$local_time <- as.POSIXct(week1_2_3_rest$local_time)


#round the local time to the closest 10 mins

week1_2_3_rest <- week1_2_3_rest %>%
  mutate(hours = substr(time, 1, 2),
         mins = substr(time, 4, 5),
         round_local_time = lubridate::round_date(local_time, "10 minutes") )


# create a df that has regular time step No sure I need this bit??
min(week1_2_3_rest$round_local_time)
max(week1_2_3_rest$round_local_time)

time_step_df <- data.frame( round_local_time =
seq(as.POSIXct(min(week1_2_3_rest$round_local_time)), #start time
    as.POSIXct(max(week1_2_3_rest$round_local_time)), #end time
    dminutes(10)) #inteval 
)

#my time step may not match the observered data how should I make it join?
#when there are multiple entries for one rounded value I could:
#1. take the unique value or take a average.
# I will try taking a unique value and see what happens

#only keep unique round time values for each animal
week1_2_3_rest_dis <- week1_2_3_rest %>% 
  group_by(deviceName) %>% 
    distinct(round_local_time, .keep_all= TRUE)

  
  
# unique(week1_2_3_rest_dis$deviceName)
# str(time_step_df)
# #if I need this bit turn it into a loop
# time_step_by_9370004 <- time_step_df %>% 
#   mutate(round_local_time_device = 
#            paste0(round_local_time, "_", "9370004"))
# time_step_by_9370088 <- time_step_df %>% 
#   mutate(round_local_time_device = 
#            paste0(round_local_time, "_", "9370088"))

#join my time step to the observed data 
#(this should ensure that if I have missing data I still have a placeholder)
#rest_template_one_animal <- left_join(time_step_df,week1_2_3_rest_dis) 


 
 week1_2_3_rest_dis <- week1_2_3_rest_dis %>% 
  dplyr::select(round_local_time, 
                deviceName,
                gpsData.lat,
                gpsData.lng, 
                resting,
                fencesID_1,
                day_since_vf_start)
                

 week1_2_3_rest_dis <- week1_2_3_rest_dis %>% 
  mutate(resting_threshold = case_when(
    resting >= 20 ~ 1,
    TRUE ~ NA_real_))


#need to make df into spatial object for graphing and try clipping to paddock boundary
# long_plains <- st_read("W:/VF/LongPlain/LP Blk Bound/LongPlain_GDA_internal_bound.shp")
# long_plains_Vf <- st_read("W:/VF/LongPlain/LP Blk Bound/LongPlainVF_bound.shp")

#str(week1_2_3)


week1_2_3_rest_dis_sf <-
  st_as_sf(week1_2_3_rest_dis,
           coords = c("gpsData.lng", "gpsData.lat"),
           crs = 4326,
           agr = "constant")

week1_2_3_rest_dis_sf_trans <-
  st_transform(week1_2_3_rest_dis_sf, crs = 28354)

week1_2_3_rest_dis_sf_trans_clip <-
  st_intersection(week1_2_3_rest_dis_sf_trans, long_plains)    
###  paddock bounadry
#assign a coord ref epsg
# st_crs(long_plains) <- 28354
# 
# #make this the epsg that will be used for all data
# the_crs <- st_crs(long_plains, asText = TRUE)
# 
# ### VF lines
# st_crs(long_plains_Vf) <- 28354




### Clip the data for VR area.
long_plains_Area_Vf1 <- long_plains_Vf %>% 
  filter(VF_Agersen == "VF1")

long_plains_Area_Vf1_VF2 <- long_plains_Vf %>% 
  filter(VF_Agersen == "VF2" | VF_Agersen == "VF1") 

long_plains_Area_Vf1_VF2_Vf3 <- long_plains_Vf %>% 
  filter( VF_Agersen == "VF3" |VF_Agersen == "VF2" | VF_Agersen == "VF1")  

long_plains_Area_Vf1_VF2_Vf3_Vf4 <- long_plains_Vf %>% 
  filter( VF_Agersen == "VF4"|VF_Agersen == "VF3" |VF_Agersen == "VF2" | VF_Agersen == "VF1")   




week1_2_3_rest_dis_clip_AreaVF1 <-
  st_intersection(week1_2_3_rest_dis_sf_trans_clip, long_plains_Area_Vf1)   
week1_2_3_rest_dis_clip_AreaVF1_2 <-
  st_intersection(week1_2_3_rest_dis_sf_trans_clip, long_plains_Area_Vf1_VF2) 
week1_2_3_rest_dis_clip_AreaVF1_2_3 <-
  st_intersection(week1_2_3_rest_dis_sf_trans_clip, long_plains_Area_Vf1_VF2_Vf3) 
week1_2_3_rest_dis_clip_AreaVF1_2_3_4 <-
  st_intersection(week1_2_3_rest_dis_sf_trans_clip, long_plains_Area_Vf1_VF2_Vf3_Vf4) 




resting_location_VF_area1 <- ggplot() +
  geom_sf(data = long_plains, color = "black", fill = NA) +
  geom_sf(data = filter(long_plains_Vf, day_since_trial_start == 1),
          color = "black", fill = NA) +
  geom_sf(data = filter(week1_2_3_rest_dis_clip_AreaVF1,!is.na(resting_threshold)),
          alpha = 0.01) +
  theme_bw()+
  theme(legend.position = "none",
        axis.ticks = element_blank(), axis.text.x = element_blank(), axis.text.y = element_blank())+
  labs(title= "VF area 1")


resting_location_VF_area1_2 <-ggplot() +
  geom_sf(data = long_plains, color = "black", fill = NA) +
  geom_sf(data = filter(long_plains_Vf, day_since_trial_start == 5),
          color = "black", fill = NA) +
  geom_sf(data = filter(week1_2_3_rest_dis_clip_AreaVF1_2,!is.na(resting_threshold)),
          alpha = 0.01) +
  theme_bw()+
  theme(legend.position = "none",
        axis.ticks = element_blank(), axis.text.x = element_blank(), axis.text.y = element_blank())+
  labs(title= "VF 2")


resting_location_VF_area1_2_3 <-ggplot() +
  geom_sf(data = long_plains, color = "black", fill = NA) +
  geom_sf(data = filter(long_plains_Vf, day_since_trial_start == 10),
          color = "black", fill = NA) +
  geom_sf(data = filter(week1_2_3_rest_dis_clip_AreaVF1_2_3,!is.na(resting_threshold)),
          alpha = 0.01) +
  theme_bw()+
  theme(legend.position = "none",
        axis.ticks = element_blank(), axis.text.x = element_blank(), axis.text.y = element_blank())+
  labs(title= "VF area 3")


resting_location_VF_area1_2_3_4 <-ggplot() +
  geom_sf(data = long_plains, color = "black", fill = NA) +
  geom_sf(data = filter(long_plains_Vf, day_since_trial_start == 14),
          color = "black", fill = NA) +
  #geom_sf(data = long_plains_Area_Vf1_VF2_Vf3_Vf4, color = "green", fill = NA) +
  geom_sf(data = filter(week1_2_3_rest_dis_clip_AreaVF1_2_3_4,!is.na(resting_threshold)),
          alpha = 0.01) +
  theme_bw()+
  theme(legend.position = "none",
        axis.ticks = element_blank(), axis.text.x = element_blank(), axis.text.y = element_blank())+
  labs(title= "VF 4")




```


```{r write up resting spots results_version1, echo=FALSE, message=FALSE, warning=FALSE}

library("cowplot")
resting_location_by_area <- plot_grid(resting_location_VF_area1, 
          resting_location_VF_area1_2, 
          resting_location_VF_area1_2_3, 
          resting_location_VF_area1_2_3_4)#, #if you want to add the below code remove the bracket and replace with ,
          #labels = c("A", "B", "C", "D"),
          #ncol = 2, nrow = 2)
resting_location_by_area


```